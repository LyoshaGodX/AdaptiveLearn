"""
–ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ –≥—Ä–∞—Ñ–∞ –Ω–∞–≤—ã–∫–æ–≤.

–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python manage.py shell
    exec(open('mlmodels/tests/test_skills_parser.py').read())
"""

import os
import sys
import django
from pathlib import Path

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Django
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'adaptive_learning.settings')
django.setup()

from skills.models import Skill, Course
from methodist.models import Task
from mlmodels.tests.parse_skills_graph import SkillsGraphParser


def test_basic_parsing():
    """–ë–∞–∑–æ–≤—ã–π —Ç–µ—Å—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≥—Ä–∞—Ñ–∞ –Ω–∞–≤—ã–∫–æ–≤...")
    
    parser = SkillsGraphParser()
    
    # –¢–µ—Å—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ –≥—Ä–∞—Ñ–∞ –Ω–∞–≤—ã–∫–æ–≤
    skills_graph = parser.parse_skills_graph()
    print(f"‚úì –ì—Ä–∞—Ñ –Ω–∞–≤—ã–∫–æ–≤: {len(skills_graph)} –Ω–∞–≤—ã–∫–æ–≤")
    
    # –¢–µ—Å—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–≤—è–∑–µ–π –∑–∞–¥–∞–Ω–∏–π
    task_skills = parser.parse_task_skills_mapping()
    print(f"‚úì –°–≤—è–∑–∏ –∑–∞–¥–∞–Ω–∏–π: {len(task_skills)} –∑–∞–¥–∞–Ω–∏–π")
    
    # –ü—Ä–æ—Å—Ç–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_prereqs = sum(len(prereqs) for prereqs in skills_graph.values())
    skills_with_prereqs = sum(1 for prereqs in skills_graph.values() if prereqs)
    
    print(f"‚úì –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ prerequisite —Å–≤—è–∑–µ–π: {total_prereqs}")
    print(f"‚úì –ù–∞–≤—ã–∫–æ–≤ —Å prerequisites: {skills_with_prereqs}")
    
    # –ü—Ä–∏–º–µ—Ä—ã –Ω–∞–≤—ã–∫–æ–≤
    print("\nüìù –ü—Ä–∏–º–µ—Ä—ã –Ω–∞–≤—ã–∫–æ–≤:")
    for i, (skill_id, prereqs) in enumerate(list(skills_graph.items())[:5]):
        skill_name = parser.skill_info[skill_id].name
        prereq_count = len(prereqs)
        tasks_count = len(parser.skill_tasks_mapping.get(skill_id, set()))
        print(f"  {i+1}. {skill_name} (prerequisites: {prereq_count}, –∑–∞–¥–∞–Ω–∏–π: {tasks_count})")
    
    return parser


def test_analysis():
    """–¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
    print("\nüîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã...")
    
    parser = test_basic_parsing()
    analysis = parser.analyze_graph_structure()
    
    print(f"‚úì –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞: {analysis['max_depth']}")
    print(f"‚úì –ö–æ—Ä–Ω–µ–≤—ã—Ö –Ω–∞–≤—ã–∫–æ–≤: {len(analysis['root_skills'])}")
    print(f"‚úì –õ–∏—Å—Ç–æ–≤—ã—Ö –Ω–∞–≤—ã–∫–æ–≤: {len(analysis['leaf_skills'])}")
    print(f"‚úì –¶–∏–∫–ª–æ–≤ –Ω–∞–π–¥–µ–Ω–æ: {len(analysis['cycles'])}")
    
    return parser


def test_learning_path():
    """–¢–µ—Å—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø—É—Ç–∏ –∏–∑—É—á–µ–Ω–∏—è"""
    print("\nüéØ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø—É—Ç–∏ –∏–∑—É—á–µ–Ω–∏—è...")
    
    parser = test_basic_parsing()
    
    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–≤—ã–∫ —Å prerequisites
    target_skill = None
    for skill_id, prereqs in parser.skills_graph.items():
        if prereqs:
            target_skill = skill_id
            break
    
    if target_skill:
        path = parser.get_skill_learning_path(target_skill)
        skill_name = parser.skill_info[target_skill].name
        
        print(f"‚úì –ü—É—Ç—å –∏–∑—É—á–µ–Ω–∏—è –¥–ª—è '{skill_name}' ({len(path)} —à–∞–≥–æ–≤):")
        for i, skill_id in enumerate(path[-5:], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5
            name = parser.skill_info[skill_id].name
            print(f"    {i}. {name}")
    else:
        print("‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∞–≤—ã–∫–æ–≤ —Å prerequisites –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    
    return parser


def test_export():
    """–¢–µ—Å—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö"""
    print("\nüíæ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö...")
    
    parser = test_basic_parsing()
    
    # –≠–∫—Å–ø–æ—Ä—Ç –≤ temp_dir
    temp_dir = Path(__file__).parent.parent.parent / 'temp_dir'
    parser.export_graph_data(str(temp_dir))
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    expected_files = ['skills_graph.json', 'skills_graph_viz.json', 'skills_graph.dot']
    created_files = []
    
    for filename in expected_files:
        filepath = temp_dir / filename
        if filepath.exists():
            created_files.append(filename)
            print(f"‚úì –°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª: {filename} ({filepath.stat().st_size} bytes)")
    
    print(f"‚úì –°–æ–∑–¥–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(created_files)}/{len(expected_files)}")
    
    return parser


def main():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    print("üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –ø–∞—Ä—Å–µ—Ä–∞ –≥—Ä–∞—Ñ–∞ –Ω–∞–≤—ã–∫–æ–≤...\n")
    
    try:
        # –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ—Å—Ç—ã
        test_basic_parsing()
        test_analysis()
        test_learning_path()
        test_export()
        
        print("\n‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—à–ª–∏ —É—Å–ø–µ—à–Ω–æ!")
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–∞—Ö: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
