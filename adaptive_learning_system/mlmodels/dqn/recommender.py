"""
DQN –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Ä–µ–∞–ª–∏–∑—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å
        if model_path:
            try:
                self.agent.q_network.load_state_dict(torch.load(model_path))
                self.agent.q_network.eval()
            except Exception as e:
                pass
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏
        self.agent.q_network.eval()—Ç–µ–º—É, –∫–æ—Ç–æ—Ä–∞—è:
1. –ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–∞ (BKT –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –∏—Å—Ç–æ—Ä–∏—è, –≥—Ä–∞—Ñ –Ω–∞–≤—ã–∫–æ–≤)
2. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é DQN –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
3. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞–Ω–∏—è—Ö
"""

import torch
import numpy as np
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime

# Django imports
from django.contrib.auth.models import User
from methodist.models import Task

# DQN imports
from .data_processor import DQNDataProcessor, DQNEnvironment
from .model import DQNConfig, create_dqn_agent


@dataclass
class StudentStateInfo:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ —Å—Ç—É–¥–µ–Ω—Ç–∞"""
    student_id: int
    bkt_params: torch.Tensor
    history: torch.Tensor
    skills_graph: torch.Tensor
    available_actions: List[int]
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    total_skills: int
    high_mastery_skills: int    # > 0.8
    medium_mastery_skills: int  # 0.5 - 0.8
    low_mastery_skills: int     # < 0.5
    
    total_attempts: int
    success_rate: float
    avg_difficulty: float
    
    total_tasks: int
    available_tasks: int
    filtered_tasks: int


@dataclass
class TaskRecommendation:
    """–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –∑–∞–¥–∞–Ω–∏—è"""
    task_id: int
    action_index: int
    q_value: float
    confidence: float
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–¥–∞–Ω–∏–∏
    difficulty: str
    task_type: str
    skills: List[int]
    estimated_time: int
    
    # –ü—Ä–∏—á–∏–Ω–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    reason: str
    skill_match_score: float


@dataclass
class RecommendationResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã"""
    student_state: StudentStateInfo
    recommendations: List[TaskRecommendation]
    model_info: Dict
    timestamp: datetime


class DQNRecommender:
    """DQN —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞"""
    
    def __init__(self, model_path: Optional[str] = None):
        """
        Args:
            model_path: –ø—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–ª—É—á–∞–π–Ω–∞—è –º–æ–¥–µ–ª—å)
        """
        self.data_processor = DQNDataProcessor()
        self.model_path = model_path
        
        # –°–æ–∑–¥–∞–µ–º DQN –∞–≥–µ–Ω—Ç–∞
        config = DQNConfig()
        config.num_actions = self.data_processor.get_num_tasks()
        num_skills = self.data_processor.get_num_skills()
        
        self.agent = create_dqn_agent(config, num_skills)        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å
        if model_path:
            try:
                self.agent.q_network.load_state_dict(torch.load(model_path))
                self.agent.q_network.eval()
                print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {model_path}")
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")
                print("üéØ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å DQN —Å –±–∞–∑–æ–≤—ã–º–∏ –≤–µ—Å–∞–º–∏")
        else:
            print("üéØ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å DQN —Å –±–∞–∑–æ–≤—ã–º–∏ –≤–µ—Å–∞–º–∏")
    
    def get_recommendations(self, student_id: int, top_k: int = 5) -> RecommendationResult:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞
        
        Args:
            student_id: ID —Å—Ç—É–¥–µ–Ω—Ç–∞
            top_k: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            
        Returns:
            RecommendationResult —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–∞
        state_data = self.data_processor.get_student_state(student_id)
        env = state_data['environment']
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        student_state = self._analyze_student_state(student_id, state_data)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç DQN
        recommendations = self._get_dqn_recommendations(state_data, env, top_k)
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        model_info = {
            'model_type': 'DQN',
            'model_path': self.model_path,
            'num_skills': self.data_processor.get_num_skills(),
            'num_tasks': self.data_processor.get_num_tasks(),
            'state_dim': student_state.bkt_params.shape,
            'history_dim': student_state.history.shape,
            'graph_dim': student_state.skills_graph.shape
        }
        
        return RecommendationResult(
            student_state=student_state,
            recommendations=recommendations,
            model_info=model_info,
            timestamp=datetime.now()
        )
    
    def _analyze_student_state(self, student_id: int, state_data: Dict) -> StudentStateInfo:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–∞"""
        bkt_params = state_data['bkt_params']
        history = state_data['history']
        skills_graph = state_data['skills_graph']
        available_actions = state_data['available_actions']
        
        # –ê–Ω–∞–ª–∏–∑ BKT –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        mastery_levels = bkt_params.squeeze().tolist()
        high_mastery = sum(1 for m in mastery_levels if m > 0.8)
        medium_mastery = sum(1 for m in mastery_levels if 0.5 <= m <= 0.8)
        low_mastery = sum(1 for m in mastery_levels if m < 0.5)
        
        # –ê–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
        total_attempts = history.shape[0] if history.numel() > 0 else 0
        success_rate = 0.0
        avg_difficulty = 0.0
        
        if total_attempts > 0:
            success_rate = (history[:, 1] == 1.0).float().mean().item()
            avg_difficulty = history[:, 2].mean().item()
        
        # –ê–Ω–∞–ª–∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∑–∞–¥–∞–Ω–∏–π
        total_tasks = self.data_processor.get_num_tasks()
        available_tasks = len(available_actions)
        filtered_tasks = total_tasks - available_tasks
        
        return StudentStateInfo(
            student_id=student_id,
            bkt_params=bkt_params,
            history=history,
            skills_graph=skills_graph,
            available_actions=available_actions,
            total_skills=len(mastery_levels),
            high_mastery_skills=high_mastery,
            medium_mastery_skills=medium_mastery,
            low_mastery_skills=low_mastery,
            total_attempts=total_attempts,
            success_rate=success_rate,
            avg_difficulty=avg_difficulty,
            total_tasks=total_tasks,
            available_tasks=available_tasks,            filtered_tasks=filtered_tasks
        )
    
    def _get_dqn_recommendations(self, state_data: Dict, env: DQNEnvironment, top_k: int) -> List[TaskRecommendation]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç DQN –º–æ–¥–µ–ª–∏"""
        bkt_params = state_data['bkt_params'].unsqueeze(0)
        history = state_data['history'].unsqueeze(0)
        available_actions = state_data['available_actions']
        
        if not available_actions:
            return []
        
        try:
            # –ö–æ–¥–∏—Ä—É–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            with torch.no_grad():
                encoded_state = self.agent.q_network.encode_state(bkt_params, history)
                q_values = self.agent.q_network(encoded_state)  # [1, num_actions]
            
            # –ü–æ–ª—É—á–∞–µ–º Q-values –¥–ª—è –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
            recommendations = []
            available_q_values = []
            
            for action_idx in available_actions:
                q_val = q_values[0, action_idx].item()
                available_q_values.append((action_idx, q_val))
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ Q-value (—É–±—ã–≤–∞–Ω–∏–µ)
            available_q_values.sort(key=lambda x: x[1], reverse=True)
            
            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —Ç–æ–ø-k –¥–µ–π—Å—Ç–≤–∏–π
            for i, (action_idx, q_val) in enumerate(available_q_values[:top_k]):
                task_id = env.action_to_task_id[action_idx]
                
                # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–¥–∞–Ω–∏–∏
                task_info = self._get_task_info(task_id, env)
                
                # –í—ã—á–∏—Å–ª—è–µ–º confidence (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π Q-value)
                min_q = min(q for _, q in available_q_values)
                max_q = max(q for _, q in available_q_values)
                confidence = (q_val - min_q) / (max_q - min_q) if max_q > min_q else 1.0
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏—á–∏–Ω—É —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                reason = self._get_recommendation_reason(task_info, state_data, i)
                
                # –í—ã—á–∏—Å–ª—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–∞–≤—ã–∫–æ–≤
                skill_match_score = self._calculate_skill_match(task_info, bkt_params.squeeze())
                
                recommendation = TaskRecommendation(
                    task_id=task_id,
                    action_index=action_idx,
                    q_value=q_val,
                    confidence=confidence,
                    difficulty=task_info['difficulty'],
                    task_type=task_info['task_type'],
                    skills=task_info['skills'],
                    estimated_time=task_info['estimated_time'],
                    reason=reason,
                    skill_match_score=skill_match_score
                )
                
                recommendations.append(recommendation)
            
            return recommendations
            
        except Exception as e:
            return []
    
    def _get_task_info(self, task_id: int, env: DQNEnvironment) -> Dict:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–¥–∞–Ω–∏–∏"""
        try:
            task = Task.objects.get(id=task_id)
            
            difficulty_map = {'beginner': '–ü—Ä–æ—Å—Ç–∞—è', 'intermediate': '–°—Ä–µ–¥–Ω—è—è', 'advanced': '–°–ª–æ–∂–Ω–∞—è'}
            type_map = {'single_choice': '–û–¥–∏–Ω–æ—á–Ω—ã–π –≤—ã–±–æ—Ä', 'multiple_choice': '–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –≤—ã–±–æ—Ä', 'true_false': '–í–µ—Ä–Ω–æ/–ù–µ–≤–µ—Ä–Ω–æ'}
            
            return {
                'difficulty': difficulty_map.get(task.difficulty, '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
                'task_type': type_map.get(task.task_type, '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
                'skills': list(env.task_to_skills.get(task_id, set())),
                'estimated_time': getattr(task, 'estimated_time', 300)
            }
        except Task.DoesNotExist:
            return {
                'difficulty': '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ',
                'task_type': '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ',
                'skills': [],
                'estimated_time': 300
            }
    
    def _get_recommendation_reason(self, task_info: Dict, state_data: Dict, rank: int) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∏—á–∏–Ω—É —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        if rank == 0:
            return "–õ—É—á—à–∏–π –≤—ã–±–æ—Ä –ø–æ –æ—Ü–µ–Ω–∫–µ DQN –º–æ–¥–µ–ª–∏"
        elif task_info['difficulty'] == '–ü—Ä–æ—Å—Ç–∞—è':
            return "–ü–æ–¥—Ö–æ–¥—è—â–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤"
        elif task_info['difficulty'] == '–°–ª–æ–∂–Ω–∞—è':
            return "–í—ã–∑–æ–≤ –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –Ω–∞–≤—ã–∫–æ–≤"
        else:
            return f"–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç #{rank + 1}"
    
    def _calculate_skill_match(self, task_info: Dict, bkt_params: torch.Tensor) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∑–∞–¥–∞–Ω–∏—è —É—Ä–æ–≤–Ω—é –Ω–∞–≤—ã–∫–æ–≤ —Å—Ç—É–¥–µ–Ω—Ç–∞"""
        skills = task_info['skills']
        if not skills:
            return 0.5
        
        skill_levels = []
        for skill_id in skills:
            skill_idx = self.data_processor.skill_to_id.get(skill_id)
            if skill_idx is not None and skill_idx < len(bkt_params):
                mastery = bkt_params[skill_idx].item()
                skill_levels.append(mastery)
        
        if not skill_levels:
            return 0.5
        
        avg_mastery = np.mean(skill_levels)
        
        # –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —É—Ä–æ–≤–Ω—é –Ω–∞–≤—ã–∫–æ–≤
        difficulty = task_info['difficulty']
        if difficulty == '–ü—Ä–æ—Å—Ç–∞—è' and avg_mastery < 0.6:
            return 0.9  # –•–æ—Ä–æ—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
        elif difficulty == '–°—Ä–µ–¥–Ω—è—è' and 0.4 <= avg_mastery <= 0.8:
            return 0.9
        elif difficulty == '–°–ª–æ–∂–Ω–∞—è' and avg_mastery > 0.7:
            return 0.9
        else:
            return 0.5  # –°—Ä–µ–¥–Ω–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ
    
    def explain_recommendation(self, recommendation: TaskRecommendation, student_state: StudentStateInfo) -> str:
        """–û–±—ä—è—Å–Ω—è–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –≤ –ø–æ–Ω—è—Ç–Ω–æ–º –≤–∏–¥–µ"""
        explanation = f"–ó–∞–¥–∞–Ω–∏–µ {recommendation.task_id}:\n"
        explanation += f"‚Ä¢ –°–ª–æ–∂–Ω–æ—Å—Ç—å: {recommendation.difficulty}\n"
        explanation += f"‚Ä¢ –¢–∏–ø: {recommendation.task_type}\n"
        explanation += f"‚Ä¢ Q-value: {recommendation.q_value:.4f}\n"
        explanation += f"‚Ä¢ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {recommendation.confidence:.1%}\n"
        explanation += f"‚Ä¢ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –Ω–∞–≤—ã–∫–∞–º: {recommendation.skill_match_score:.1%}\n"
        explanation += f"‚Ä¢ –ü—Ä–∏—á–∏–Ω–∞: {recommendation.reason}\n"
        
        if recommendation.skills:
            explanation += f"‚Ä¢ –†–∞–∑–≤–∏–≤–∞–µ–º—ã–µ –Ω–∞–≤—ã–∫–∏: {recommendation.skills}\n"
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —É—Ä–æ–≤–Ω–∏ —ç—Ç–∏—Ö –Ω–∞–≤—ã–∫–æ–≤
            for skill_id in recommendation.skills:
                skill_idx = self.data_processor.skill_to_id.get(skill_id)
                if skill_idx is not None and skill_idx < len(student_state.bkt_params):
                    mastery = student_state.bkt_params[skill_idx, 0].item()
                    explanation += f"  - –ù–∞–≤—ã–∫ {skill_id}: {mastery:.1%} –æ—Å–≤–æ–µ–Ω–∏—è\n"
        
        return explanation
