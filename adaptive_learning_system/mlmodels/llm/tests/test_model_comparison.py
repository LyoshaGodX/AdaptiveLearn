#!/usr/bin/env python3
"""
Ğ¢ĞµÑÑ‚ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… LLM Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹

Ğ¡Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°ĞµÑ‚ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğ¹ Ğ¼ĞµĞ¶Ğ´Ñƒ:
- Qwen2.5-0.5B-Instruct
- Phi-3.5-mini-instruct  
- saiga_mistral_7b (ĞµÑĞ»Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ°)
"""

import os
import sys
from pathlib import Path
import time
from typing import Dict, List

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿ÑƒÑ‚ÑŒ Ğº Django Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ñƒ
sys.path.append(str(Path(__file__).parent.parent.parent.parent))

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Django
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'adaptive_learning.settings')

import django
django.setup()

from mlmodels.llm.explanation_generator import ExplanationGenerator
from mlmodels.llm.model_manager import LLMModelManager


def print_separator(title: str, char="=", length=80):
    """ĞšÑ€Ğ°ÑĞ¸Ğ²Ñ‹Ğ¹ Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒ"""
    print(f"\n{char * length}")
    print(f"{title.center(length)}")  
    print(f"{char * length}")


def test_model_comparison():
    """Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… LLM Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹"""
    print_separator("ğŸ† Ğ¡Ğ ĞĞ’ĞĞ•ĞĞ˜Ğ• LLM ĞœĞĞ”Ğ•Ğ›Ğ•Ğ™", "ğŸ”¥")
    
    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
    supported_models = LLMModelManager.list_supported_models()
    
    print("ğŸ“‹ Ğ”ĞĞ¡Ğ¢Ğ£ĞŸĞĞ«Ğ• ĞœĞĞ”Ğ•Ğ›Ğ˜:")
    for key, info in supported_models.items():
        print(f"   ğŸ¤– {key}:")
        print(f"      ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ: {info['model_name']}")
        print(f"      Ğ Ğ°Ğ·Ğ¼ĞµÑ€: {info['size_gb']} GB")
        print(f"      ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ: {info['description']}")
    
    # Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ
    test_data = {
        'student_name': 'Ğ•Ğ»ĞµĞ½Ğ°',
        'task_title': 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¸ÑĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğ¹ Ğ² Python',
        'task_difficulty': 'intermediate',
        'target_skill_info': [{
            'skill_name': 'ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº',
            'current_mastery_probability': 0.3
        }],
        'prerequisite_skills_snapshot': [
            {'skill_name': 'ĞÑĞ½Ğ¾Ğ²Ñ‹ Python', 'mastery_probability': 0.8},
            {'skill_name': 'Ğ£ÑĞ»Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ñ‹', 'mastery_probability': 0.7}
        ],
        'student_progress_context': {
            'total_success_rate': 0.6
        }
    }
    
    print(f"\nğŸ“ Ğ¢Ğ•Ğ¡Ğ¢ĞĞ’Ğ«Ğ• Ğ”ĞĞĞĞ«Ğ•:")
    print(f"   Ğ¡Ñ‚ÑƒĞ´ĞµĞ½Ñ‚: {test_data['student_name']}")
    print(f"   Ğ—Ğ°Ğ´Ğ°Ğ½Ğ¸Ğµ: {test_data['task_title']}")
    print(f"   Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ: {test_data['task_difficulty']}")
    print(f"   Ğ¦ĞµĞ»ĞµĞ²Ğ¾Ğ¹ Ğ½Ğ°Ğ²Ñ‹Ğº: {test_data['target_skill_info'][0]['skill_name']}")
    print(f"   ĞÑĞ²Ğ¾ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ: {test_data['target_skill_info'][0]['current_mastery_probability']:.1%}")
    
    # ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ (Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµĞ¼ Ñ ÑĞ°Ğ¼Ğ¾Ğ¹ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾Ğ¹)
    models_to_test = ['qwen2.5-0.5b']  # Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒÑ‚Ğµ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ Ğ¿Ğ¾ Ğ¶ĞµĞ»Ğ°Ğ½Ğ¸Ñ
    
    results = {}
    
    for model_key in models_to_test:
        print_separator(f"Ğ¢Ğ•Ğ¡Ğ¢ ĞœĞĞ”Ğ•Ğ›Ğ˜: {model_key.upper()}", "ğŸš€")
        
        try:
            print(f"ğŸ”„ Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ {model_key}...")
            start_time = time.time()
            
            generator = ExplanationGenerator(model_key=model_key, device='auto')
            
            if not generator.is_initialized:
                print("â³ Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ...")
                success = generator.initialize(use_quantization=True)
                
                if not success:
                    print(f"âŒ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ {model_key}")
                    continue
            
            init_time = time.time() - start_time
            print(f"âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ° Ğ·Ğ° {init_time:.1f} ÑĞµĞºÑƒĞ½Ğ´")
            
            # Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ñ
            print("ğŸ¤– Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ñ...")
            gen_start = time.time()
            
            explanation = generator.generate_recommendation_explanation(test_data)
            
            gen_time = time.time() - gen_start
            
            print(f"\nğŸ“ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢ ({model_key}):")
            print("â”Œ" + "â”€" * 78 + "â”")
            if explanation:
                words = explanation.split()
                current_line = ""
                for word in words:
                    if len(current_line + " " + word) <= 76:
                        current_line += (" " + word if current_line else word)
                    else:
                        print(f"â”‚ {current_line:<76} â”‚")
                        current_line = word
                if current_line:
                    print(f"â”‚ {current_line:<76} â”‚")
            else:
                print("â”‚ [ĞĞ¨Ğ˜Ğ‘ĞšĞ Ğ˜Ğ›Ğ˜ ĞŸĞ£Ğ¡Ğ¢ĞĞ™ ĞĞ¢Ğ’Ğ•Ğ¢]                                           â”‚")
            print("â””" + "â”€" * 78 + "â”˜")
            
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
            results[model_key] = {
                'explanation': explanation,
                'init_time': init_time,
                'generation_time': gen_time,
                'length': len(explanation) if explanation else 0,
                'word_count': len(explanation.split()) if explanation else 0,
                'success': bool(explanation and len(explanation.strip()) > 10)
            }
            
            print(f"\nğŸ“Š ĞœĞ•Ğ¢Ğ Ğ˜ĞšĞ˜:")
            print(f"   Ğ’Ñ€ĞµĞ¼Ñ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸: {init_time:.1f} ÑĞµĞº")
            print(f"   Ğ’Ñ€ĞµĞ¼Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸: {gen_time:.2f} ÑĞµĞº")
            print(f"   Ğ”Ğ»Ğ¸Ğ½Ğ°: {results[model_key]['length']} ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²")
            print(f"   Ğ¡Ğ»Ğ¾Ğ²: {results[model_key]['word_count']}")
            print(f"   ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾: {'âœ…' if results[model_key]['success'] else 'âŒ'}")
            
        except Exception as e:
            print(f"ğŸ’¥ ĞĞ¨Ğ˜Ğ‘ĞšĞ Ğ¿Ñ€Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸ {model_key}: {e}")
            results[model_key] = {
                'explanation': None,
                'init_time': 0,
                'generation_time': 0,
                'length': 0,
                'word_count': 0,
                'success': False,
                'error': str(e)
            }
    
    # Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ğµ ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ
    if len(results) > 1:
        print_separator("ğŸ“Š Ğ˜Ğ¢ĞĞ“ĞĞ’ĞĞ• Ğ¡Ğ ĞĞ’ĞĞ•ĞĞ˜Ğ•", "ğŸ†")
        
        print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("â”‚ ĞœĞ¾Ğ´ĞµĞ»ÑŒ          â”‚ Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ». â”‚ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†. â”‚ Ğ”Ğ»Ğ¸Ğ½Ğ°   â”‚ Ğ¡Ğ»Ğ¾Ğ²Ğ° â”‚ Ğ£ÑĞ¿ĞµÑ…   â”‚")
        print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        
        for model_key, result in results.items():
            name = model_key[:15]
            init_time = f"{result['init_time']:.1f}Ñ" if result['success'] else "ĞĞ¨Ğ˜Ğ‘ĞšĞ"
            gen_time = f"{result['generation_time']:.2f}Ñ" if result['success'] else "N/A"
            length = str(result['length'])
            words = str(result['word_count'])
            success = "âœ…" if result['success'] else "âŒ"
            
            print(f"â”‚ {name:<15} â”‚ {init_time:>8} â”‚ {gen_time:>8} â”‚ {length:>7} â”‚ {words:>5} â”‚ {success:>7} â”‚")
        
        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        
        # Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸
        fastest_init = min((k for k, v in results.items() if v['success']), 
                          key=lambda k: results[k]['init_time'], default=None)
        fastest_gen = min((k for k, v in results.items() if v['success']), 
                         key=lambda k: results[k]['generation_time'], default=None)
        
        print(f"\nğŸ† Ğ Ğ•ĞšĞĞœĞ•ĞĞ”ĞĞ¦Ğ˜Ğ˜:")
        if fastest_init:
            print(f"   ğŸš€ Ğ‘Ñ‹ÑÑ‚Ñ€ĞµĞ¹ÑˆĞ°Ñ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ: {fastest_init}")
        if fastest_gen:
            print(f"   âš¡ Ğ‘Ñ‹ÑÑ‚Ñ€ĞµĞ¹ÑˆĞ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ: {fastest_gen}")
        
        successful_models = [k for k, v in results.items() if v['success']]
        if successful_models:
            best_quality = max(successful_models, 
                             key=lambda k: results[k]['length'] if 150 <= results[k]['length'] <= 250 else 0)
            print(f"   â­ Ğ›ÑƒÑ‡ÑˆĞµĞµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ (Ğ¿Ğ¾ Ğ´Ğ»Ğ¸Ğ½Ğµ): {best_quality}")


def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ"""
    print_separator("ğŸ§ª Ğ¡Ğ ĞĞ’ĞĞ˜Ğ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ™ Ğ¢Ğ•Ğ¡Ğ¢ LLM ĞœĞĞ”Ğ•Ğ›Ğ•Ğ™", "ğŸ”¬")
    
    print("ğŸ“ ĞĞŸĞ˜Ğ¡ĞĞĞ˜Ğ•:")
    print("   Ğ­Ñ‚Ğ¾Ñ‚ Ñ‚ĞµÑÑ‚ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾")
    print("   Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… LLM Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ğ±ÑŠÑÑĞ½ĞµĞ½Ğ¸Ğ¹.")
    print("   ")
    print("âš ï¸  Ğ’ĞĞ˜ĞœĞĞĞ˜Ğ•:")
    print("   - Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ½ÑÑ‚ÑŒ Ğ²Ñ€ĞµĞ¼Ñ")
    print("   - Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ ÑĞ²Ğ¾Ğ±Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸")
    print("   - ĞĞµĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ±Ñ‹Ñ‚ÑŒ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹")
    
    try:
        input("\nğŸ‘† ĞĞ°Ğ¶Ğ¼Ğ¸Ñ‚Ğµ Enter Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸Ğ»Ğ¸ Ctrl+C Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¼ĞµĞ½Ñ‹...")
        test_model_comparison()
        
        print_separator("âœ… Ğ¡Ğ ĞĞ’ĞĞ˜Ğ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ™ Ğ¢Ğ•Ğ¡Ğ¢ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•Ğ", "ğŸ‰")
        
    except KeyboardInterrupt:
        print("\n\nâŒ Ğ¢ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€ĞµÑ€Ğ²Ğ°Ğ½Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼")
    except Exception as e:
        print(f"\n\nğŸ’¥ ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ¯ ĞĞ¨Ğ˜Ğ‘ĞšĞ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
