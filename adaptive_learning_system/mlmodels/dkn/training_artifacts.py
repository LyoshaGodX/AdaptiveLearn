"""
–ú–æ–¥—É–ª—å –¥–ª—è —Å–±–æ—Ä–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è DKN –º–æ–¥–µ–ª–∏.

–í–∫–ª—é—á–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è:
- –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è
- –°–±–æ—Ä–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏ –º–µ—Ç—Ä–∏–∫
- –°–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–æ–≤ –æ–± –æ–±—É—á–µ–Ω–∏–∏
- –ê–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import json
import torch
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import plotly.io as pio
from sklearn.metrics import (
    confusion_matrix, classification_report, 
    roc_curve, auc, precision_recall_curve
)
import warnings
warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª–µ–π
plt.style.use('default')
sns.set_palette("husl")


class TrainingArtifactsCollector:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–±–æ—Ä–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è DKN –º–æ–¥–µ–ª–∏"""
    
    def __init__(self, artifacts_dir: str = "mlmodels/dkn/training"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        
        Args:
            artifacts_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        """
        self.artifacts_dir = Path(artifacts_dir)
        self.artifacts_dir.mkdir(parents=True, exist_ok=True)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        self.plots_dir = self.artifacts_dir / "plots"
        self.metrics_dir = self.artifacts_dir / "metrics"
        self.models_dir = self.artifacts_dir / "models"
        self.reports_dir = self.artifacts_dir / "reports"
        
        for dir_path in [self.plots_dir, self.metrics_dir, self.models_dir, self.reports_dir]:
            dir_path.mkdir(exist_ok=True)
        
        # –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        self.training_history = {
            'train_loss': [],
            'val_loss': [],
            'train_accuracy': [],
            'val_accuracy': [],
            'learning_rate': [],
            'epoch': [],
            'timestamp': []
        }
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ —ç–ø–æ—Ö–∞–º
        self.epoch_metrics = []
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–±—É—á–µ–Ω–∏–∏
        self.training_info = {
            'start_time': None,
            'end_time': None,
            'total_epochs': 0,
            'best_epoch': 0,
            'best_val_loss': float('inf'),
            'best_val_accuracy': 0.0,
            'early_stopped': False,
            'final_model_path': None
        }
    
    def log_epoch(self, epoch: int, train_loss: float, val_loss: float,
                  train_accuracy: float, val_accuracy: float, 
                  learning_rate: float, additional_metrics: Dict = None):
        """
        –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —ç–ø–æ—Ö–∏
        
        Args:
            epoch: –ù–æ–º–µ—Ä —ç–ø–æ—Ö–∏
            train_loss: –ü–æ—Ç–µ—Ä–∏ –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏
            val_loss: –ü–æ—Ç–µ—Ä–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            train_accuracy: –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏
            val_accuracy: –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            learning_rate: –¢–µ–∫—É—â–∏–π learning rate
            additional_metrics: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        """
        timestamp = datetime.now()
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏
        self.training_history['epoch'].append(epoch)
        self.training_history['train_loss'].append(train_loss)
        self.training_history['val_loss'].append(val_loss)
        self.training_history['train_accuracy'].append(train_accuracy)
        self.training_history['val_accuracy'].append(val_accuracy)
        self.training_history['learning_rate'].append(learning_rate)
        self.training_history['timestamp'].append(timestamp.isoformat())
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ —ç–ø–æ—Ö–∏
        epoch_data = {
            'epoch': epoch,
            'train_loss': train_loss,
            'val_loss': val_loss,
            'train_accuracy': train_accuracy,
            'val_accuracy': val_accuracy,
            'learning_rate': learning_rate,
            'timestamp': timestamp.isoformat()
        }
        
        if additional_metrics:
            epoch_data.update(additional_metrics)
        
        self.epoch_metrics.append(epoch_data)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –º–µ—Ç—Ä–∏–∫
        if val_loss < self.training_info['best_val_loss']:
            self.training_info['best_val_loss'] = val_loss
            self.training_info['best_epoch'] = epoch
        
        if val_accuracy > self.training_info['best_val_accuracy']:
            self.training_info['best_val_accuracy'] = val_accuracy
    
    def create_training_curves(self, save_plot: bool = True) -> go.Figure:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤ –∫—Ä–∏–≤—ã—Ö –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            save_plot: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ –≤ —Ñ–∞–π–ª
            
        Returns:
            Plotly Figure –æ–±—ä–µ–∫—Ç
        """
        fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=('–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å', '–¢–æ—á–Ω–æ—Å—Ç—å', 'Learning Rate', '–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫'),
            specs=[[{"secondary_y": False}, {"secondary_y": False}],
                   [{"secondary_y": False}, {"secondary_y": True}]]
        )
        
        epochs = self.training_history['epoch']
        
        # –ì—Ä–∞—Ñ–∏–∫ –ø–æ—Ç–µ—Ä—å
        fig.add_trace(
            go.Scatter(x=epochs, y=self.training_history['train_loss'],
                      name='Train Loss', line=dict(color='blue')),
            row=1, col=1
        )
        fig.add_trace(
            go.Scatter(x=epochs, y=self.training_history['val_loss'],
                      name='Val Loss', line=dict(color='red')),
            row=1, col=1
        )
        
        # –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏
        fig.add_trace(
            go.Scatter(x=epochs, y=self.training_history['train_accuracy'],
                      name='Train Accuracy', line=dict(color='green')),
            row=1, col=2
        )
        fig.add_trace(
            go.Scatter(x=epochs, y=self.training_history['val_accuracy'],
                      name='Val Accuracy', line=dict(color='orange')),
            row=1, col=2
        )
        
        # –ì—Ä–∞—Ñ–∏–∫ learning rate
        fig.add_trace(
            go.Scatter(x=epochs, y=self.training_history['learning_rate'],
                      name='Learning Rate', line=dict(color='purple')),
            row=2, col=1
        )
        
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫
        fig.add_trace(
            go.Scatter(x=epochs, y=self.training_history['val_loss'],
                      name='Val Loss', line=dict(color='red')),
            row=2, col=2
        )
        fig.add_trace(
            go.Scatter(x=epochs, y=self.training_history['val_accuracy'],
                      name='Val Accuracy', line=dict(color='orange'),
                      yaxis='y2'),
            row=2, col=2, secondary_y=True
        )
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–∞–∫–µ—Ç–æ–≤
        fig.update_xaxes(title_text="–≠–ø–æ—Ö–∞")
        fig.update_yaxes(title_text="–ü–æ—Ç–µ—Ä–∏", row=1, col=1)
        fig.update_yaxes(title_text="–¢–æ—á–Ω–æ—Å—Ç—å", row=1, col=2)
        fig.update_yaxes(title_text="Learning Rate", row=2, col=1)
        fig.update_yaxes(title_text="–ü–æ—Ç–µ—Ä–∏", row=2, col=2)
        fig.update_yaxes(title_text="–¢–æ—á–Ω–æ—Å—Ç—å", row=2, col=2, secondary_y=True)
        
        fig.update_layout(
            title_text="–ö—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è DKN –º–æ–¥–µ–ª–∏",
            showlegend=True,
            height=800
        )
        
        if save_plot:
            plot_path = self.plots_dir / "training_curves.html"
            fig.write_html(str(plot_path))
            
            # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω–∏–º PNG –≤–µ—Ä—Å–∏—é
            png_path = self.plots_dir / "training_curves.png"
            pio.write_image(fig, str(png_path), width=1200, height=800)
        
        return fig
    
    def create_metrics_dashboard(self, test_predictions: np.ndarray = None,
                               test_targets: np.ndarray = None,
                               save_plot: bool = True) -> go.Figure:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—à–±–æ—Ä–¥–∞ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –º–æ–¥–µ–ª–∏
        
        Args:
            test_predictions: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
            test_targets: –¶–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏
            save_plot: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≥—Ä–∞—Ñ–∏–∫ –≤ —Ñ–∞–π–ª
            
        Returns:
            Plotly Figure –æ–±—ä–µ–∫—Ç
        """
        if test_predictions is not None and test_targets is not None:
            # ROC –∫—Ä–∏–≤–∞—è
            fpr, tpr, _ = roc_curve(test_targets, test_predictions)
            roc_auc = auc(fpr, tpr)
            
            # Precision-Recall –∫—Ä–∏–≤–∞—è
            precision, recall, _ = precision_recall_curve(test_targets, test_predictions)
            pr_auc = auc(recall, precision)
            
            # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
            y_pred_binary = (test_predictions > 0.5).astype(int)
            cm = confusion_matrix(test_targets, y_pred_binary)
            
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('ROC –ö—Ä–∏–≤–∞—è', 'Precision-Recall –ö—Ä–∏–≤–∞—è', 
                              '–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫', '–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π'),
                specs=[[{"type": "scatter"}, {"type": "scatter"}],
                       [{"type": "heatmap"}, {"type": "histogram"}]]
            )
            
            # ROC –∫—Ä–∏–≤–∞—è
            fig.add_trace(
                go.Scatter(x=fpr, y=tpr,
                          name=f'ROC (AUC = {roc_auc:.3f})',
                          line=dict(color='blue')),
                row=1, col=1
            )
            fig.add_trace(
                go.Scatter(x=[0, 1], y=[0, 1],
                          name='–°–ª—É—á–∞–π–Ω—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä',
                          line=dict(color='red', dash='dash')),
                row=1, col=1
            )
            
            # Precision-Recall –∫—Ä–∏–≤–∞—è
            fig.add_trace(
                go.Scatter(x=recall, y=precision,
                          name=f'PR (AUC = {pr_auc:.3f})',
                          line=dict(color='green')),
                row=1, col=2
            )
            
            # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
            fig.add_trace(
                go.Heatmap(z=cm, x=['Predicted 0', 'Predicted 1'],
                          y=['Actual 0', 'Actual 1'],
                          colorscale='Blues', showscale=True),
                row=2, col=1
            )
            
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
            fig.add_trace(
                go.Histogram(x=test_predictions[test_targets == 0],
                           name='–ö–ª–∞—Å—Å 0', opacity=0.7, nbinsx=50),
                row=2, col=2
            )
            fig.add_trace(
                go.Histogram(x=test_predictions[test_targets == 1],
                           name='–ö–ª–∞—Å—Å 1', opacity=0.7, nbinsx=50),
                row=2, col=2
            )
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è
            fig = make_subplots(
                rows=1, cols=2,
                subplot_titles=('–ò—Å—Ç–æ—Ä–∏—è –ø–æ—Ç–µ—Ä—å', '–ò—Å—Ç–æ—Ä–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏')
            )
            
            epochs = self.training_history['epoch']
            
            fig.add_trace(
                go.Scatter(x=epochs, y=self.training_history['train_loss'],
                          name='Train Loss', line=dict(color='blue')),
                row=1, col=1
            )
            fig.add_trace(
                go.Scatter(x=epochs, y=self.training_history['val_loss'],
                          name='Val Loss', line=dict(color='red')),
                row=1, col=1
            )
            
            fig.add_trace(
                go.Scatter(x=epochs, y=self.training_history['train_accuracy'],
                          name='Train Accuracy', line=dict(color='green')),
                row=1, col=2
            )
            fig.add_trace(
                go.Scatter(x=epochs, y=self.training_history['val_accuracy'],
                          name='Val Accuracy', line=dict(color='orange')),
                row=1, col=2
            )
        
        fig.update_layout(
            title_text="–î–∞—à–±–æ—Ä–¥ –º–µ—Ç—Ä–∏–∫ DKN –º–æ–¥–µ–ª–∏",
            showlegend=True,
            height=800
        )
        
        if save_plot:
            plot_path = self.plots_dir / "metrics_dashboard.html"
            fig.write_html(str(plot_path))
            
            png_path = self.plots_dir / "metrics_dashboard.png"
            pio.write_image(fig, str(png_path), width=1200, height=800)
        
        return fig
    
    def save_training_statistics(self, additional_stats: Dict = None):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è –≤ JSON —Ñ–∞–π–ª
        
        Args:
            additional_stats: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        stats = {
            'training_info': self.training_info,
            'training_history': self.training_history,
            'final_metrics': {
                'best_val_loss': self.training_info['best_val_loss'],
                'best_val_accuracy': self.training_info['best_val_accuracy'],
                'best_epoch': self.training_info['best_epoch'],
                'total_epochs': len(self.training_history['epoch'])
            }
        }
        
        if additional_stats:
            stats.update(additional_stats)
        
        stats_path = self.metrics_dir / "training_statistics.json"
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
    
    def save_epoch_metrics(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø–æ —ç–ø–æ—Ö–∞–º –≤ CSV —Ñ–∞–π–ª"""
        df = pd.DataFrame(self.epoch_metrics)
        csv_path = self.metrics_dir / "epoch_metrics.csv"
        df.to_csv(csv_path, index=False)
    
    def generate_training_report(self, model_config: Dict = None,
                               dataset_info: Dict = None,
                               test_metrics: Dict = None) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏
        
        Args:
            model_config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
            dataset_info: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
            test_metrics: –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É –æ—Ç—á–µ—Ç—É
        """
        report_content = self._create_report_content(
            model_config, dataset_info, test_metrics
        )
        
        report_path = self.reports_dir / "training_report.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        return str(report_path)
    
    def _create_report_content(self, model_config: Dict = None,
                             dataset_info: Dict = None,
                             test_metrics: Dict = None) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏"""
        
        start_time = self.training_info.get('start_time', 'N/A')
        end_time = self.training_info.get('end_time', 'N/A')
        
        if start_time != 'N/A' and end_time != 'N/A':
            duration = pd.to_datetime(end_time) - pd.to_datetime(start_time)
            duration_str = str(duration)
        else:
            duration_str = 'N/A'
        
        report = f"""# –û—Ç—á–µ—Ç –æ–± –æ–±—É—á–µ–Ω–∏–∏ DKN –º–æ–¥–µ–ª–∏

## üìä –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞**: {datetime.now().strftime('%d.%m.%Y %H:%M')}
**–í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –æ–±—É—á–µ–Ω–∏—è**: {start_time}
**–í—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è**: {end_time}
**–ü—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å**: {duration_str}

## üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è

### –õ—É—á—à–∏–µ –º–µ—Ç—Ä–∏–∫–∏
- **–õ—É—á—à–∞—è —ç–ø–æ—Ö–∞**: {self.training_info['best_epoch']}
- **–õ—É—á—à–∏–µ –ø–æ—Ç–µ—Ä–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏**: {self.training_info['best_val_loss']:.6f}
- **–õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏**: {self.training_info['best_val_accuracy']:.4f}
- **–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö**: {len(self.training_history['epoch'])}
- **Early stopping**: {'–î–∞' if self.training_info.get('early_stopped', False) else '–ù–µ—Ç'}

### –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
- **–§–∏–Ω–∞–ª—å–Ω—ã–µ –ø–æ—Ç–µ—Ä–∏ –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏**: {self.training_history['train_loss'][-1]:.6f if self.training_history['train_loss'] else 'N/A'}
- **–§–∏–Ω–∞–ª—å–Ω—ã–µ –ø–æ—Ç–µ—Ä–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏**: {self.training_history['val_loss'][-1]:.6f if self.training_history['val_loss'] else 'N/A'}
- **–§–∏–Ω–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏**: {self.training_history['train_accuracy'][-1]:.4f if self.training_history['train_accuracy'] else 'N/A'}
- **–§–∏–Ω–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏**: {self.training_history['val_accuracy'][-1]:.4f if self.training_history['val_accuracy'] else 'N/A'}

"""

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        if model_config:
            report += f"""## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏

```json
{json.dumps(model_config, indent=2, ensure_ascii=False)}
```

"""

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ
        if dataset_info:
            report += f"""## üìö –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞—Ç–∞—Å–µ—Ç–µ

```json
{json.dumps(dataset_info, indent=2, ensure_ascii=False)}
```

"""

        # –¢–µ—Å—Ç–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        if test_metrics:
            report += f"""## üß™ –ú–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ

```json
{json.dumps(test_metrics, indent=2, ensure_ascii=False)}
```

"""

        # –§–∞–π–ª—ã –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        report += f"""## üìÅ –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –æ–±—É—á–µ–Ω–∏—è

### –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
- `plots/training_curves.html` - –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –∫—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è
- `plots/training_curves.png` - –ö—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è (PNG)
- `plots/metrics_dashboard.html` - –î–∞—à–±–æ—Ä–¥ –º–µ—Ç—Ä–∏–∫
- `plots/metrics_dashboard.png` - –î–∞—à–±–æ—Ä–¥ –º–µ—Ç—Ä–∏–∫ (PNG)

### –ú–µ—Ç—Ä–∏–∫–∏ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
- `metrics/training_statistics.json` - –ü–æ–ª–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è
- `metrics/epoch_metrics.csv` - –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ —ç–ø–æ—Ö–∞–º

### –ú–æ–¥–µ–ª–∏
- `models/best_model.pth` - –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å
- `models/final_model.pth` - –§–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å
- `models/model_config.json` - –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏

### –û—Ç—á–µ—Ç—ã
- `reports/training_report.md` - –≠—Ç–æ—Ç –æ—Ç—á–µ—Ç

## üìà –ê–Ω–∞–ª–∏–∑ –æ–±—É—á–µ–Ω–∏—è

### –°—Ö–æ–¥–∏–º–æ—Å—Ç—å
{'–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —Å–æ—à–ª–∞—Å—å' if self.training_info['best_val_loss'] < float('inf') else '–ü—Ä–æ–±–ª–µ–º—ã —Å–æ —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å—é'}

### –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
{self._analyze_overfitting()}

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
{self._generate_recommendations()}

---

*–û—Ç—á–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∏—Å—Ç–µ–º–æ–π TrainingArtifactsCollector*
"""

        return report
    
    def _analyze_overfitting(self) -> str:
        """–ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"""
        if not self.training_history['train_loss'] or not self.training_history['val_loss']:
            return "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"
        
        final_train_loss = self.training_history['train_loss'][-1]
        final_val_loss = self.training_history['val_loss'][-1]
        
        if final_val_loss > final_train_loss * 1.2:
            return "‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ - –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–æ—Ç–µ—Ä–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –≤—ã—à–µ –æ–±—É—á–∞—é—â–∏—Ö"
        elif final_val_loss > final_train_loss * 1.1:
            return "‚ö†Ô∏è –õ–µ–≥–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è"
        else:
            return "‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ"
    
    def _generate_recommendations(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        recommendations = []
        
        if not self.training_history['val_accuracy']:
            return "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"
        
        best_val_acc = max(self.training_history['val_accuracy'])
        
        if best_val_acc < 0.6:
            recommendations.append("‚Ä¢ –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏ –∏–ª–∏ —É–ª—É—á—à–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã")
        
        if self.training_info.get('early_stopped', False):
            recommendations.append("‚Ä¢ –û–±—É—á–µ–Ω–∏–µ –±—ã–ª–æ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ early stopping - –≤–æ–∑–º–æ–∂–Ω–æ —Å—Ç–æ–∏—Ç —É–≤–µ–ª–∏—á–∏—Ç—å patience")
        
        if len(self.training_history['epoch']) < 10:
            recommendations.append("‚Ä¢ –û–±—É—á–µ–Ω–∏–µ –±—ã–ª–æ –∫–æ—Ä–æ—Ç–∫–∏–º - —Ä–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ø–æ—Ö")
        
        final_train_loss = self.training_history['train_loss'][-1]
        final_val_loss = self.training_history['val_loss'][-1]
        
        if final_val_loss > final_train_loss * 1.2:
            recommendations.append("‚Ä¢ –î–æ–±–∞–≤—å—Ç–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –∏–ª–∏ dropout –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º")
        
        if not recommendations:
            recommendations.append("‚Ä¢ –û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—à–ª–æ —É—Å–ø–µ—à–Ω–æ, –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–µ—Ç")
        
        return "\n".join(recommendations)
    
    def finalize_training(self, end_time: str = None, early_stopped: bool = False):
        """
        –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            end_time: –í—Ä–µ–º—è –æ–∫–æ–Ω—á–∞–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è
            early_stopped: –ë—ã–ª–æ –ª–∏ –æ–±—É—á–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ early stopping
        """
        self.training_info['end_time'] = end_time or datetime.now().isoformat()
        self.training_info['early_stopped'] = early_stopped
        self.training_info['total_epochs'] = len(self.training_history['epoch'])
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        self.save_training_statistics()
        self.save_epoch_metrics()
        self.create_training_curves()
        self.create_metrics_dashboard()
    
    def set_training_start(self, start_time: str = None):
        """
        –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞—á–∞–ª–∞ –æ–±—É—á–µ–Ω–∏—è
        
        Args:
            start_time: –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –æ–±—É—á–µ–Ω–∏—è
        """
        self.training_info['start_time'] = start_time or datetime.now().isoformat()


def create_training_artifacts_collector(artifacts_dir: str = "mlmodels/dkn/training") -> TrainingArtifactsCollector:
    """
    –§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ç–æ—Ä–∞ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
    
    Args:
        artifacts_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        
    Returns:
        –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π TrainingArtifactsCollector
    """
    return TrainingArtifactsCollector(artifacts_dir)
