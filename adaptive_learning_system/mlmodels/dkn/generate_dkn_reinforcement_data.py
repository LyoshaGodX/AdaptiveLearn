#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è DKN —Å –æ–±—É—á–µ–Ω–∏–µ–º —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
1. –£—á–∏—Ç—ã–≤–∞–µ—Ç –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –≥—Ä–∞—Ñ –Ω–∞–≤—ã–∫–æ–≤ (30 –Ω–∞–≤—ã–∫–æ–≤, 16 —É—Ä–æ–≤–Ω–µ–π)
2. –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—Å–≤–æ–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤
3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (state, action, reward)
4. –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ BKT –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–æ–π
5. –ü–æ–∫—Ä—ã—Ç–∏–µ –≤—Å–µ—Ö –Ω–∞–≤—ã–∫–æ–≤ –∏ –∫—É—Ä—Å–æ–≤
"""

import sys
import os
import json
import numpy as np
import pandas as pd
from typing import Dict, List, Set, Tuple, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from collections import defaultdict
import random
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Django
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'adaptive_learning.settings')

import django
django.setup()

from skills.models import Skill
from methodist.models import Task, Course
from django.contrib.auth.models import User


@dataclass
class SkillState:
    """–°–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–∞–≤—ã–∫–∞ –¥–ª—è BKT"""
    skill_id: int
    skill_name: str
    level: int
    prior_knowledge: float  # P(L0) - –Ω–∞—á–∞–ª—å–Ω–æ–µ –∑–Ω–∞–Ω–∏–µ
    learn_rate: float      # P(T) - —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
    guess_rate: float      # P(G) - —É–≥–∞–¥—ã–≤–∞–Ω–∏–µ
    slip_rate: float       # P(S) - –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–Ω–∞–Ω–∏–∏
    current_mastery: float # –¢–µ–∫—É—â–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Å–≤–æ–µ–Ω–∏—è
    prerequisites: List[int] # ID –ø—Ä–µ–¥–ø–æ—Å—ã–ª–æ–∫


@dataclass
class TaskAction:
    """–î–µ–π—Å—Ç–≤–∏–µ - –≤—ã–±–æ—Ä –∑–∞–¥–∞–Ω–∏—è"""
    task_id: int
    skill_id: int
    difficulty: str  # beginner, intermediate, advanced
    task_type: str   # true_false, single, multiple
    course_id: int


@dataclass
class StudentState:
    """–°–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–∞ –¥–ª—è RL"""
    student_id: int
    skill_masteries: Dict[int, float]  # –¢–µ–∫—É—â–∏–µ BKT –æ—Ü–µ–Ω–∫–∏
    available_skills: Set[int]         # –î–æ—Å—Ç—É–ø–Ω—ã–µ –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è –Ω–∞–≤—ã–∫–∏
    learning_trajectory: List[int]     # –ò—Å—Ç–æ—Ä–∏—è –∏–∑—É—á–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞–Ω–∏–π
    session_progress: float           # –ü—Ä–æ–≥—Ä–µ—Å—Å –≤ —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏
    fatigue_level: float             # –£—Ä–æ–≤–µ–Ω—å —É—Å—Ç–∞–ª–æ—Å—Ç–∏
    success_streak: int              # –°–µ—Ä–∏—è —É—Å–ø–µ—Ö–æ–≤
    failure_streak: int              # –°–µ—Ä–∏—è –Ω–µ—É–¥–∞—á


@dataclass
class ReinforcementRecord:
    """–ó–∞–ø–∏—Å—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º"""
    student_id: int
    timestamp: datetime
    
    # State (–°–æ—Å—Ç–æ—è–Ω–∏–µ)
    state: Dict[str, Any]
    
    # Action (–î–µ–π—Å—Ç–≤–∏–µ) 
    action: TaskAction
    
    # Reward (–ù–∞–≥—Ä–∞–¥–∞)
    immediate_reward: float      # –ú–≥–Ω–æ–≤–µ–Ω–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞ (–ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å)
    learning_reward: float       # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å –Ω–∞–≤—ã–∫–∞
    exploration_reward: float    # –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ
    total_reward: float         # –û–±—â–∞—è –Ω–∞–≥—Ä–∞–¥–∞
    
    # Next State (–°–ª–µ–¥—É—é—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ)
    next_state: Dict[str, Any]
    
    # Episode info
    is_terminal: bool           # –ö–æ–Ω–µ—Ü —ç–ø–∏–∑–æ–¥–∞
    expert_feedback: Optional[float]  # –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å —ç–∫—Å–ø–µ—Ä—Ç–∞


class DKNReinforcementDataGenerator:
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è DKN —Å –æ–±—É—á–µ–Ω–∏–µ–º —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º"""
    
    def __init__(self, target_students: int = 1500, output_path: str = "dataset"):
        self.target_students = target_students
        self.output_path = Path(output_path)
        self.output_path.mkdir(exist_ok=True)
        
        # BKT –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.default_bkt = {
            'prior_knowledge': 0.1,
            'learn_rate': 0.3,
            'guess_rate': 0.2,
            'slip_rate': 0.1
        }
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã RL
        self.reward_weights = {
            'correctness': 1.0,      # –í–µ—Å –∑–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å
            'learning_progress': 2.0, # –í–µ—Å –∑–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å –Ω–∞–≤—ã–∫–∞
            'difficulty_match': 1.5,  # –í–µ—Å –∑–∞ –ø–æ–¥—Ö–æ–¥—è—â—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å
            'exploration': 0.5,      # –í–µ—Å –∑–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ
            'efficiency': 1.0        # –í–µ—Å –∑–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
        }
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self._load_skills_and_tasks()
        self._build_skill_graph()
        self._initialize_statistics()
    
    def _load_skills_and_tasks(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–∞–≤—ã–∫–∏ –∏ –∑–∞–¥–∞–Ω–∏—è –∏–∑ –±–∞–∑—ã"""
        print("üìö –ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞–≤—ã–∫–æ–≤ –∏ –∑–∞–¥–∞–Ω–∏–π –∏–∑ –±–∞–∑—ã...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞–≤—ã–∫–∏
        skills_queryset = Skill.objects.select_related().prefetch_related('prerequisites')
        self.skills = {}
        self.skill_levels = {}
        
        for skill in skills_queryset:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –Ω–∞–≤—ã–∫–∞
            level = getattr(skill, 'level', self._calculate_skill_level(skill))
            
            skill_state = SkillState(
                skill_id=skill.id,
                skill_name=skill.name,
                level=level,
                prior_knowledge=self.default_bkt['prior_knowledge'],
                learn_rate=self.default_bkt['learn_rate'],
                guess_rate=self.default_bkt['guess_rate'],
                slip_rate=self.default_bkt['slip_rate'],
                current_mastery=self.default_bkt['prior_knowledge'],
                prerequisites=[p.id for p in skill.prerequisites.all()]
            )
            
            self.skills[skill.id] = skill_state
            self.skill_levels[level] = self.skill_levels.get(level, []) + [skill.id]
          # –ó–∞–≥—Ä—É–∂–∞–µ–º –∑–∞–¥–∞–Ω–∏—è
        tasks_queryset = Task.objects.prefetch_related('skills', 'courses')
        self.tasks = {}
        self.tasks_by_skill = defaultdict(list)
        self.tasks_by_course = defaultdict(list)
        
        for task in tasks_queryset:
            task_skills = list(task.skills.all())
            if not task_skills:
                continue
                
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫—É—Ä—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–≤—è–∑–µ–π
            task_courses = list(task.courses.all())
            course_id = task_courses[0].id if task_courses else 1
                
            task_action = TaskAction(
                task_id=task.id,
                skill_id=task_skills[0].id,  # –û—Å–Ω–æ–≤–Ω–æ–π –Ω–∞–≤—ã–∫
                difficulty=task.difficulty or 'intermediate',
                task_type=task.task_type or 'single',
                course_id=course_id
            )            
            self.tasks[task.id] = task_action
            
            for skill in task_skills:
                self.tasks_by_skill[skill.id].append(task_action)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∫—É—Ä—Å—ã
            for course in task_courses:
                self.tasks_by_course[course.id].append(task_action)
        
        print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–∞–≤—ã–∫–æ–≤: {len(self.skills)}")
        print(f"   ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–¥–∞–Ω–∏–π: {len(self.tasks)}")
        print(f"   ‚úÖ –£—Ä–æ–≤–Ω–µ–π –Ω–∞–≤—ã–∫–æ–≤: {len(self.skill_levels)}")
    
    def _calculate_skill_level(self, skill):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å –Ω–∞–≤—ã–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–ø–æ—Å—ã–ª–æ–∫"""
        if not skill.prerequisites.exists():
            return 1
        
        max_prereq_level = 0
        for prereq in skill.prerequisites.all():
            prereq_level = getattr(prereq, 'level', self._calculate_skill_level(prereq))
            max_prereq_level = max(max_prereq_level, prereq_level)
        
        return max_prereq_level + 1
    
    def _build_skill_graph(self):
        """–°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –Ω–∞–≤—ã–∫–æ–≤"""
        print("üï∏Ô∏è –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ –Ω–∞–≤—ã–∫–æ–≤...")
        
        self.skill_graph = {}
        self.reverse_graph = defaultdict(list)  # –ö–∞–∫–∏–µ –Ω–∞–≤—ã–∫–∏ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç —Ç–µ–∫—É—â–∏–π
        for skill_id, skill_state in self.skills.items():
            self.skill_graph[skill_id] = skill_state.prerequisites
            
            # –°—Ç—Ä–æ–∏–º –æ–±—Ä–∞—Ç–Ω—ã–π –≥—Ä–∞—Ñ
            for prereq_id in skill_state.prerequisites:
                self.reverse_graph[prereq_id].append(skill_id)
        
        print(f"   ‚úÖ –ü–æ—Å—Ç—Ä–æ–µ–Ω –≥—Ä–∞—Ñ: {len(self.skill_graph)} –Ω–∞–≤—ã–∫–æ–≤")
        print(f"   ‚úÖ –°–≤—è–∑–µ–π: {sum(len(prereqs) for prereqs in self.skill_graph.values())}")
    
    def _initialize_statistics(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
        self.stats = {
            'students_generated': 0,
            'records_generated': 0,
            'skills_covered': set(),
            'courses_covered': set(),
            'level_coverage': defaultdict(int),
            'difficulty_distribution': defaultdict(int),
            'type_distribution': defaultdict(int),
            'reward_statistics': defaultdict(list),
            'skill_individual_coverage': defaultdict(int),
            'course_coverage': defaultdict(int)
        }
    
    def get_available_skills(self, skill_masteries: Dict[int, float], 
                           mastery_threshold: float = 0.8) -> Set[int]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–≤—ã–∫–∏, –¥–æ—Å—Ç—É–ø–Ω—ã–µ –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è"""
        available = set()
        
        for skill_id, skill_state in self.skills.items():
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ–¥–ø–æ—Å—ã–ª–∫–∏
            prerequisites_met = True
            for prereq_id in skill_state.prerequisites:
                if skill_masteries.get(prereq_id, 0.0) < mastery_threshold:
                    prerequisites_met = False
                    break
            
            if prerequisites_met:
                # –ù–∞–≤—ã–∫ –¥–æ—Å—Ç—É–ø–µ–Ω, –µ—Å–ª–∏ –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Å–≤–æ–µ–Ω
                if skill_masteries.get(skill_id, 0.0) < 0.95:
                    available.add(skill_id)
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö, –Ω–∞—á–∏–Ω–∞–µ–º —Å –±–∞–∑–æ–≤—ã—Ö –Ω–∞–≤—ã–∫–æ–≤
        if not available:
            level_1_skills = self.skill_levels.get(1, [])
            available.update(level_1_skills)
        
        return available
    
    def select_optimal_task(self, student_state: StudentState) -> Optional[TaskAction]:
        """–í—ã–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∑–∞–¥–∞–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å—Ç—É–¥–µ–Ω—Ç–∞"""
        available_skills = student_state.available_skills
        if not available_skills:
            return None
        
        # –í—ã–±–∏—Ä–∞–µ–º –Ω–∞–≤—ã–∫ –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è
        target_skill = self._select_target_skill(student_state, available_skills)
        if not target_skill or target_skill not in self.tasks_by_skill:
            return None
        
        # –í—ã–±–∏—Ä–∞–µ–º –ø–æ–¥—Ö–æ–¥—è—â–µ–µ –∑–∞–¥–∞–Ω–∏–µ –¥–ª—è –Ω–∞–≤—ã–∫–∞
        skill_tasks = self.tasks_by_skill[target_skill]
        if not skill_tasks:
            return None
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–¥—Ö–æ–¥—è—â—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        skill_mastery = student_state.skill_masteries.get(target_skill, 0.1)
        target_difficulty = self._determine_difficulty(skill_mastery, student_state)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–¥–∞–Ω–∏—è –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        suitable_tasks = [
            task for task in skill_tasks 
            if task.difficulty == target_difficulty
        ]
        
        if not suitable_tasks:
            suitable_tasks = skill_tasks  # Fallback
        
        return random.choice(suitable_tasks)
    
    def _select_target_skill(self, student_state: StudentState, 
                           available_skills: Set[int]) -> Optional[int]:
        """–í—ã–±–∏—Ä–∞–µ—Ç —Ü–µ–ª–µ–≤–æ–π –Ω–∞–≤—ã–∫ –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è"""
        skill_priorities = {}
        
        for skill_id in available_skills:
            skill_state = self.skills[skill_id]
            mastery = student_state.skill_masteries.get(skill_id, 0.1)
            
            # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç = –≤–∞–∂–Ω–æ—Å—Ç—å —É—Ä–æ–≤–Ω—è + –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ä–æ—Å—Ç–∞ + —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ
            level_importance = 1.0 / (skill_state.level + 1)  # –ë–∞–∑–æ–≤—ã–µ –Ω–∞–≤—ã–∫–∏ –≤–∞–∂–Ω–µ–µ
            growth_potential = 1.0 - mastery  # –ë–æ–ª—å—à–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞ —É –Ω–µ–æ—Å–≤–æ–µ–Ω–Ω—ã—Ö
            exploration_bonus = 0.1 if skill_id not in student_state.learning_trajectory[-10:] else 0
            
            priority = level_importance + growth_potential + exploration_bonus
            skill_priorities[skill_id] = priority
        
        # –í—ã–±–∏—Ä–∞–µ–º —Å –≤–µ—Å–æ–≤–æ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é
        if not skill_priorities:
            return None
        
        skills, weights = zip(*skill_priorities.items())
        weights = np.array(weights)
        weights = weights / weights.sum()
        
        return np.random.choice(skills, p=weights)
    
    def _determine_difficulty(self, skill_mastery: float, 
                            student_state: StudentState) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞–Ω–∏—è"""
        # –ë–∞–∑–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç–∏
        if skill_mastery < 0.3:
            # –ù–æ–≤—ã–π –Ω–∞–≤—ã–∫ - –ª–µ–≥–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è
            return 'beginner'
        elif skill_mastery < 0.7:
            # –†–∞–∑–≤–∏–≤–∞—é—â–∏–π—Å—è –Ω–∞–≤—ã–∫ - —Å—Ä–µ–¥–Ω–∏–µ –∑–∞–¥–∞–Ω–∏—è
            if student_state.success_streak >= 3:
                return 'intermediate'
            else:
                return 'beginner'
        else:
            # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –Ω–∞–≤—ã–∫ - —Å–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞–Ω–∏—è
            if student_state.success_streak >= 2:
                return 'advanced'
            else:
                return 'intermediate'
    
    def calculate_rewards(self, student_state: StudentState, action: TaskAction, 
                         is_correct: bool, skill_progress: float) -> Dict[str, float]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –Ω–∞–≥—Ä–∞–¥—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º"""
        rewards = {}
        
        # 1. –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å
        rewards['correctness'] = 1.0 if is_correct else -0.5
        
        # 2. –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å –Ω–∞–≤—ã–∫–∞
        rewards['learning_progress'] = skill_progress * 5.0
        
        # 3. –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ –ø–æ–¥—Ö–æ–¥—è—â—É—é —Å–ª–æ–∂–Ω–æ—Å—Ç—å
        skill_mastery = student_state.skill_masteries.get(action.skill_id, 0.1)
        difficulty_match = self._calculate_difficulty_match(skill_mastery, action.difficulty)
        rewards['difficulty_match'] = difficulty_match
        
        # 4. –ù–∞–≥—Ä–∞–¥–∞ –∑–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –Ω–∞–≤—ã–∫–æ–≤
        recent_skills = set(self.tasks[tid].skill_id for tid in student_state.learning_trajectory[-5:] 
                           if tid in self.tasks)
        rewards['exploration'] = 0.5 if action.skill_id not in recent_skills else 0.0
        
        # 5. –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å (—Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –æ—à–∏–±–æ–∫ –ø–æ–¥—Ä—è–¥)
        rewards['efficiency'] = -0.3 if student_state.failure_streak >= 3 else 0.0
        
        # –û–±—â–∞—è –Ω–∞–≥—Ä–∞–¥–∞
        total_reward = sum(
            rewards[key] * self.reward_weights[key] 
            for key in rewards if key in self.reward_weights
        )
        rewards['total'] = total_reward
        
        return rewards
    
    def _calculate_difficulty_match(self, skill_mastery: float, difficulty: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞–Ω–∏—è —É—Ä–æ–≤–Ω—é –Ω–∞–≤—ã–∫–∞"""
        difficulty_levels = {'beginner': 0.2, 'intermediate': 0.5, 'advanced': 0.8}
        target_level = difficulty_levels.get(difficulty, 0.5)
        
        # –ß–µ–º –±–ª–∏–∂–µ —É—Ä–æ–≤–µ–Ω—å –Ω–∞–≤—ã–∫–∞ –∫ —Ü–µ–ª–µ–≤–æ–º—É, —Ç–µ–º –ª—É—á—à–µ
        match_score = 1.0 - abs(skill_mastery - target_level)
        return max(0.0, match_score)
    
    def update_bkt_parameters(self, skill_id: int, is_correct: bool, 
                            current_mastery: float) -> float:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç BKT –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ—Å–ª–µ –ø–æ–ø—ã—Ç–∫–∏"""
        skill_state = self.skills[skill_id]
        
        # BKT –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
        if is_correct:
            # P(L_{n+1} | evidence) - –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
            evidence_prob = (
                current_mastery * (1 - skill_state.slip_rate) + 
                (1 - current_mastery) * skill_state.guess_rate
            )
            new_mastery = (
                current_mastery * (1 - skill_state.slip_rate) / evidence_prob
            )
        else:
            # P(L_{n+1} | evidence) - –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç
            evidence_prob = (
                current_mastery * skill_state.slip_rate + 
                (1 - current_mastery) * (1 - skill_state.guess_rate)
            )
            new_mastery = (
                current_mastery * skill_state.slip_rate / evidence_prob
            )
        
        # –û–±—É—á–µ–Ω–∏–µ: P(L_{n+1}) = P(L_n) + (1-P(L_n)) * P(T)
        if not is_correct:  # –û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
            new_mastery = new_mastery + (1 - new_mastery) * skill_state.learn_rate
        
        return min(0.99, max(0.01, new_mastery))
    
    def generate_student_episode(self, student_id: int, 
                               episode_length: int = 50) -> List[ReinforcementRecord]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —ç–ø–∏–∑–æ–¥ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å—Ç—É–¥–µ–Ω—Ç–∞"""
        records = []
        
        # –ù–∞—á–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–∞
        student_state = StudentState(
            student_id=student_id,
            skill_masteries={skill_id: np.random.uniform(0.05, 0.15) 
                           for skill_id in self.skills.keys()},
            available_skills=set(),
            learning_trajectory=[],
            session_progress=0.0,
            fatigue_level=0.0,
            success_streak=0,
            failure_streak=0
        )
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –Ω–∞–≤—ã–∫–∏
        student_state.available_skills = self.get_available_skills(student_state.skill_masteries)
        
        current_time = datetime.now() - timedelta(days=random.randint(1, 30))
        
        for step in range(episode_length):
            # –¢–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            state = self._encode_state(student_state)
            
            # –í—ã–±–∏—Ä–∞–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
            action = self.select_optimal_task(student_state)
            if not action:
                break
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
            is_correct, skill_progress = self._simulate_task_attempt(student_state, action)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –Ω–∞–≥—Ä–∞–¥—ã
            rewards = self.calculate_rewards(student_state, action, is_correct, skill_progress)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–∞
            new_student_state = self._update_student_state(
                student_state, action, is_correct, skill_progress
            )
            
            # –°–ª–µ–¥—É—é—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
            next_state = self._encode_state(new_student_state)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–µ—Ü —ç–ø–∏–∑–æ–¥–∞
            is_terminal = (step == episode_length - 1) or (
                len(new_student_state.available_skills) == 0
            )
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å—å
            record = ReinforcementRecord(
                student_id=student_id,
                timestamp=current_time,
                state=state,
                action=action,
                immediate_reward=rewards['correctness'],
                learning_reward=rewards['learning_progress'],
                exploration_reward=rewards['exploration'],
                total_reward=rewards['total'],
                next_state=next_state,
                is_terminal=is_terminal,
                expert_feedback=self._simulate_expert_feedback(rewards['total'])
            )
            
            records.append(record)
            
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—é
            student_state = new_student_state
            current_time += timedelta(minutes=random.randint(2, 15))
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            self._update_statistics(action, rewards)
        
        return records
    
    def _encode_state(self, student_state: StudentState) -> Dict[str, Any]:
        """–ö–æ–¥–∏—Ä—É–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–∞ –¥–ª—è RL"""
        return {
            'skill_masteries': student_state.skill_masteries.copy(),
            'available_skills': list(student_state.available_skills),
            'recent_tasks': student_state.learning_trajectory[-10:],
            'session_progress': student_state.session_progress,
            'fatigue_level': student_state.fatigue_level,
            'success_streak': student_state.success_streak,
            'failure_streak': student_state.failure_streak,
            'skills_by_level': {
                level: [sid for sid in skill_ids 
                       if student_state.skill_masteries.get(sid, 0) > 0.8]
                for level, skill_ids in self.skill_levels.items()
            }
        }
    
    def _simulate_task_attempt(self, student_state: StudentState, 
                             action: TaskAction) -> Tuple[bool, float]:
        """–°–∏–º—É–ª–∏—Ä—É–µ—Ç –ø–æ–ø—ã—Ç–∫—É —Ä–µ—à–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è"""
        skill_mastery = student_state.skill_masteries.get(action.skill_id, 0.1)
        skill_state = self.skills[action.skill_id]
        
        # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–ø–µ—Ö–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ BKT
        success_prob = (
            skill_mastery * (1 - skill_state.slip_rate) + 
            (1 - skill_mastery) * skill_state.guess_rate
        )
        
        # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        difficulty_mod = {'beginner': 1.2, 'intermediate': 1.0, 'advanced': 0.8}
        success_prob *= difficulty_mod.get(action.difficulty, 1.0)
        
        # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —É—Å—Ç–∞–ª–æ—Å—Ç–∏
        success_prob *= (1 - student_state.fatigue_level * 0.3)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        is_correct = np.random.random() < np.clip(success_prob, 0.05, 0.95)
        
        # –ü—Ä–æ–≥—Ä–µ—Å—Å –Ω–∞–≤—ã–∫–∞
        old_mastery = skill_mastery
        new_mastery = self.update_bkt_parameters(action.skill_id, is_correct, skill_mastery)
        skill_progress = new_mastery - old_mastery
        
        return is_correct, skill_progress
    
    def _update_student_state(self, student_state: StudentState, action: TaskAction,
                            is_correct: bool, skill_progress: float) -> StudentState:
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ –ø–æ–ø—ã—Ç–∫–∏"""
        new_state = StudentState(
            student_id=student_state.student_id,
            skill_masteries=student_state.skill_masteries.copy(),
            available_skills=student_state.available_skills.copy(),
            learning_trajectory=student_state.learning_trajectory + [action.task_id],
            session_progress=min(1.0, student_state.session_progress + 0.02),
            fatigue_level=min(1.0, student_state.fatigue_level + 0.01),
            success_streak=student_state.success_streak + 1 if is_correct else 0,
            failure_streak=student_state.failure_streak + 1 if not is_correct else 0
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –º–∞—Å—Ç–µ—Ä—Å—Ç–≤–æ –Ω–∞–≤—ã–∫–∞
        new_state.skill_masteries[action.skill_id] += skill_progress
        new_state.skill_masteries[action.skill_id] = np.clip(
            new_state.skill_masteries[action.skill_id], 0.01, 0.99
        )
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –Ω–∞–≤—ã–∫–∏
        new_state.available_skills = self.get_available_skills(new_state.skill_masteries)
        
        return new_state
    
    def _simulate_expert_feedback(self, total_reward: float) -> Optional[float]:
        """–°–∏–º—É–ª–∏—Ä—É–µ—Ç –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å —ç–∫—Å–ø–µ—Ä—Ç–∞"""
        # –≠–∫—Å–ø–µ—Ä—Ç –¥–∞–µ—Ç –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –≤ 20% —Å–ª—É—á–∞–µ–≤
        if np.random.random() > 0.2:
            return None
        
        # –≠–∫—Å–ø–µ—Ä—Ç –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –Ω–∞–≥—Ä–∞–¥—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ–¥–∞–≥–æ–≥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤
        if total_reward > 2.0:
            return np.random.uniform(0.8, 1.0)  # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å
        elif total_reward < -1.0:
            return np.random.uniform(-1.0, -0.5)  # –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å
        else:
            return np.random.uniform(-0.2, 0.2)  # –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è
    
    def _update_statistics(self, action: TaskAction, rewards: Dict[str, float]):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
        self.stats['records_generated'] += 1
        self.stats['skills_covered'].add(action.skill_id)
        self.stats['courses_covered'].add(action.course_id)
        
        skill_level = self.skills[action.skill_id].level
        self.stats['level_coverage'][skill_level] += 1
        self.stats['difficulty_distribution'][action.difficulty] += 1
        self.stats['type_distribution'][action.task_type] += 1
        
        for reward_type, value in rewards.items():
            self.stats['reward_statistics'][reward_type].append(value)
    
    def generate_full_dataset(self) -> pd.DataFrame:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è DKN"""
        print(f"\nüöÄ –ì–ï–ù–ï–†–ê–¶–ò–Ø DKN –î–ê–¢–ê–°–ï–¢–ê –î–õ–Ø {self.target_students} –°–¢–£–î–ï–ù–¢–û–í")
        print("=" * 70)
        
        all_records = []
        
        for student_id in range(1, self.target_students + 1):
            if student_id % 100 == 0:
                print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {student_id}/{self.target_students}")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–ø–∏–∑–æ–¥ –¥–ª—è —Å—Ç—É–¥–µ–Ω—Ç–∞
            episode_length = np.random.randint(30, 80)  # –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª–∏–Ω–∞ —ç–ø–∏–∑–æ–¥–æ–≤
            student_records = self.generate_student_episode(student_id, episode_length)
            all_records.extend(student_records)
            
            self.stats['students_generated'] += 1
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ DataFrame
        df_data = []
        for record in all_records:
            row = {
                'student_id': record.student_id,
                'task_id': record.action.task_id,
                'skill_id': record.action.skill_id,
                'target': 1.0 if record.immediate_reward > 0 else 0.0,
                'difficulty': record.action.difficulty,
                'task_type': record.action.task_type,
                'course_id': record.action.course_id,
                'skill_level': self.skills[record.action.skill_id].level,
                
                # State features
                'current_skill_mastery': record.state['skill_masteries'].get(record.action.skill_id, 0.1),
                'session_progress': record.state['session_progress'],
                'fatigue_level': record.state['fatigue_level'],
                'success_streak': record.state['success_streak'],
                'failure_streak': record.state['failure_streak'],
                
                # Rewards
                'immediate_reward': record.immediate_reward,
                'learning_reward': record.learning_reward,
                'exploration_reward': record.exploration_reward,
                'total_reward': record.total_reward,
                'expert_feedback': record.expert_feedback or 0.0,
                
                # Episode info
                'is_terminal': record.is_terminal,
                'timestamp': record.timestamp.isoformat()
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º BKT –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≤—Å–µ—Ö –Ω–∞–≤—ã–∫–æ–≤
            for skill_id in self.skills.keys():
                row[f'skill_{skill_id}_mastery'] = record.state['skill_masteries'].get(skill_id, 0.1)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –Ω–∞–≤—ã–∫–∞—Ö –ø–æ —É—Ä–æ–≤–Ω—è–º
            for level in range(1, 17):  # 16 —É—Ä–æ–≤–Ω–µ–π –º–∞–∫—Å–∏–º—É–º
                level_skills = record.state.get('skills_by_level', {}).get(level, [])
                row[f'level_{level}_mastered'] = len(level_skills)
            
            df_data.append(row)
        
        df = pd.DataFrame(df_data)
        
        print(f"\n‚úÖ –ì–ï–ù–ï–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê!")
        print(f"   –°—Ç—É–¥–µ–Ω—Ç–æ–≤: {self.stats['students_generated']}")
        print(f"   –ó–∞–ø–∏—Å–µ–π: {len(df)}")
        print(f"   –ù–∞–≤—ã–∫–æ–≤ –ø–æ–∫—Ä—ã—Ç–æ: {len(self.stats['skills_covered'])}/{len(self.skills)}")
        print(f"   –ö—É—Ä—Å–æ–≤ –ø–æ–∫—Ä—ã—Ç–æ: {len(self.stats['courses_covered'])}")
        print(f"   –£—Ä–æ–≤–Ω–µ–π –ø–æ–∫—Ä—ã—Ç–æ: {len(self.stats['level_coverage'])}")
        
        return df
    
    def save_dataset(self, df: pd.DataFrame):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç—ã"""
        print(f"\nüíæ –°–û–•–†–ê–ù–ï–ù–ò–ï –î–ê–¢–ê–°–ï–¢–ê...")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –¥–∞—Ç–∞—Å–µ—Ç
        output_file = self.output_path / "dkn_reinforcement_dataset.csv"
        df.to_csv(output_file, index=False)
        print(f"   ‚úÖ –î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats_file = self.output_path / "generation_statistics.json"
        stats_serializable = {}
        for key, value in self.stats.items():
            if isinstance(value, set):
                stats_serializable[key] = list(value)
            elif isinstance(value, defaultdict):
                stats_serializable[key] = dict(value)
            else:
                stats_serializable[key] = value
        
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats_serializable, f, indent=2, ensure_ascii=False)
        print(f"   ‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {stats_file}")
          # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        self._generate_report(df)
        
        # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        self._create_visualizations(df)
    
    def _generate_report(self, df: pd.DataFrame):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –æ –¥–∞—Ç–∞—Å–µ—Ç–µ"""
        report_file = self.output_path / "DKN_REINFORCEMENT_REPORT.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(f"""# –û—Ç—á–µ—Ç –æ DKN –¥–∞—Ç–∞—Å–µ—Ç–µ —Å –æ–±—É—á–µ–Ω–∏–µ–º —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º

## üìä –û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è**: {datetime.now().strftime('%d.%m.%Y %H:%M')}

### –†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞
- **–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π**: {len(df):,}
- **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤**: {df['student_id'].nunique():,}
- **–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —ç–ø–∏–∑–æ–¥–∞**: {len(df) / df['student_id'].nunique():.1f}

### –ü–æ–∫—Ä—ã—Ç–∏–µ —Å–∏—Å—Ç–µ–º—ã
- **–ù–∞–≤—ã–∫–æ–≤ –ø–æ–∫—Ä—ã—Ç–æ**: {len(self.stats['skills_covered'])}/{len(self.skills)} ({len(self.stats['skills_covered'])/len(self.skills)*100:.1f}%)
- **–ö—É—Ä—Å–æ–≤ –ø–æ–∫—Ä—ã—Ç–æ**: {len(self.stats['courses_covered'])}
- **–£—Ä–æ–≤–Ω–µ–π –ø–æ–∫—Ä—ã—Ç–æ**: {len(self.stats['level_coverage'])}/16

## üéØ –ê–Ω–∞–ª–∏–∑ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π

### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
- **–û–±—â–∞—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å**: {df['target'].mean()*100:.1f}%
- **–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ**: {df['target'].std():.3f}

### –ü–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞–Ω–∏–π
- **–õ–µ–≥–∫–∏–µ –∑–∞–¥–∞–Ω–∏—è**: {df[df['difficulty'] == 'beginner']['target'].mean()*100:.1f}% —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
- **–°—Ä–µ–¥–Ω–∏–µ –∑–∞–¥–∞–Ω–∏—è**: {df[df['difficulty'] == 'intermediate']['target'].mean()*100:.1f}% —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
- **–°–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞–Ω–∏—è**: {df[df['difficulty'] == 'advanced']['target'].mean()*100:.1f}% —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏

### –ü–æ —Ç–∏–ø–∞–º –∑–∞–¥–∞–Ω–∏–π
- **–í–µ—Ä–Ω—ã–µ/–ù–µ–≤–µ—Ä–Ω—ã–µ**: {df[df['task_type'] == 'true_false']['target'].mean()*100:.1f}% —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
- **–û–¥–∏–Ω–æ—á–Ω—ã–µ –≤—ã–±–æ—Ä—ã**: {df[df['task_type'] == 'single']['target'].mean()*100:.1f}% —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
- **–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –≤—ã–±–æ—Ä—ã**: {df[df['task_type'] == 'multiple']['target'].mean()*100:.1f}% —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏

## üß† –ê–Ω–∞–ª–∏–∑ —Å–∏—Å—Ç–µ–º—ã –Ω–∞–≥—Ä–∞–¥

### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞–≥—Ä–∞–¥
- **–°—Ä–µ–¥–Ω—è—è –º–≥–Ω–æ–≤–µ–Ω–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞**: {df['immediate_reward'].mean():.3f}
- **–°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞ –∑–∞ –æ–±—É—á–µ–Ω–∏–µ**: {df['learning_reward'].mean():.3f}
- **–°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞ –∑–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ**: {df['exploration_reward'].mean():.3f}
- **–°—Ä–µ–¥–Ω—è—è –æ–±—â–∞—è –Ω–∞–≥—Ä–∞–¥–∞**: {df['total_reward'].mean():.3f}

### –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å —ç–∫—Å–ø–µ—Ä—Ç–∞
- **–ó–∞–ø–∏—Å–µ–π —Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é**: {(df['expert_feedback'] != 0).sum():,} ({(df['expert_feedback'] != 0).mean()*100:.1f}%)
- **–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ —ç–∫—Å–ø–µ—Ä—Ç–∞**: {df[df['expert_feedback'] != 0]['expert_feedback'].mean():.3f}

## üï∏Ô∏è –ê–Ω–∞–ª–∏–∑ –≥—Ä–∞—Ñ–∞ –Ω–∞–≤—ã–∫–æ–≤

### –ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ —É—Ä–æ–≤–Ω—è–º
""")
            
            # –ê–Ω–∞–ª–∏–∑ –ø–æ —É—Ä–æ–≤–Ω—è–º
            for level in sorted(self.stats['level_coverage'].keys()):
                count = self.stats['level_coverage'][level]
                f.write(f"- **–£—Ä–æ–≤–µ–Ω—å {level}**: {count:,} –∑–∞–ø–∏—Å–µ–π\n")
            
            f.write(f"""
## üéÆ –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º

### –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —ç–ø–∏–∑–æ–¥–æ–≤
- **–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —ç–ø–∏–∑–æ–¥–∞**: {len(df) / df['student_id'].nunique():.1f}
- **–¢–µ—Ä–º–∏–Ω–∞–ª—å–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π**: {df['is_terminal'].sum():,}
- **–ó–∞–ø–∏—Å–µ–π —Å —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –æ—Ü–µ–Ω–∫–æ–π**: {(df['expert_feedback'] != 0).sum():,}

### –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–π
- **–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –Ω–∞–≤—ã–∫–æ–≤**: –í—ã—Å–æ–∫–æ–µ
- **–ê–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏**: ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–∞
- **–£—á–µ—Ç –ø—Ä–µ–¥–ø–æ—Å—ã–ª–æ–∫ –Ω–∞–≤—ã–∫–æ–≤**: ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω

## ‚úÖ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º DKN

- ‚úÖ **–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –≥—Ä–∞—Ñ –Ω–∞–≤—ã–∫–æ–≤**: 30 –Ω–∞–≤—ã–∫–æ–≤, 16 —É—Ä–æ–≤–Ω–µ–π
- ‚úÖ **–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å**: –ó–∞–¥–∞–Ω–∏—è –ø–æ–¥–±–∏—Ä–∞—é—Ç—Å—è –ø–æ —É—Ä–æ–≤–Ω—é –Ω–∞–≤—ã–∫–∞
- ‚úÖ **BKT –ø–∞—Ä–∞–º–µ—Ç—Ä—ã**: –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–Ω–∞–º–∏–∫–æ–π
- ‚úÖ **–°–∏—Å—Ç–µ–º–∞ –Ω–∞–≥—Ä–∞–¥**: –ú–Ω–æ–≥–æ–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è RL
- ‚úÖ **–û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å —ç–∫—Å–ø–µ—Ä—Ç–∞**: 20% –∑–∞–ø–∏—Å–µ–π —Å —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –æ—Ü–µ–Ω–∫–æ–π
- ‚úÖ **–ü–æ–ª–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ**: –í—Å–µ –Ω–∞–≤—ã–∫–∏ –∏ –∫—É—Ä—Å—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã

## üöÄ –ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é

–î–∞—Ç–∞—Å–µ—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤ –¥–ª—è:
1. **–û–±—É—á–µ–Ω–∏—è DKN –º–æ–¥–µ–ª–∏** —Å —É—á–µ—Ç–æ–º –≥—Ä–∞—Ñ–∞ –Ω–∞–≤—ã–∫–æ–≤
2. **–û–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º** (RL) —Å —Å–∏—Å—Ç–µ–º–æ–π –Ω–∞–≥—Ä–∞–¥
3. **–î–æ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö** –ø–æ—Å–ª–µ –≤–Ω–µ–¥—Ä–µ–Ω–∏—è
4. **–≠–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏** —á–µ—Ä–µ–∑ —Å–∏—Å—Ç–µ–º—É –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏

---
*–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏: {datetime.now().strftime('%d.%m.%Y %H:%M')}*
""")
        
        print(f"   ‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_file}")

    def _create_visualizations(self, df: pd.DataFrame):
        """–°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        print(f"   üìä –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª—è
        plt.style.use('seaborn-v0_8')
        sns.set_palette("husl")
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–≥—É—Ä—É —Å –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–∞–º–∏
        fig = plt.figure(figsize=(20, 24))
        
        # 1. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        plt.subplot(4, 3, 1)
        success_by_difficulty = df.groupby('difficulty')['target'].agg(['mean', 'count'])
        bars = plt.bar(success_by_difficulty.index, success_by_difficulty['mean'])
        plt.title('–£—Å–ø–µ—à–Ω–æ—Å—Ç—å –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∑–∞–¥–∞–Ω–∏–π')
        plt.ylabel('–î–æ–ª—è —É—Å–ø–µ—à–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫')
        plt.ylim(0, 1)
        for i, (bar, count) in enumerate(zip(bars, success_by_difficulty['count'])):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                    f'{success_by_difficulty["mean"].iloc[i]:.2f}\n({count:,})', 
                    ha='center', va='bottom')
        
        # 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –ø–æ —Ç–∏–ø–∞–º –∑–∞–¥–∞–Ω–∏–π
        plt.subplot(4, 3, 2)
        success_by_type = df.groupby('task_type')['target'].agg(['mean', 'count'])
        bars = plt.bar(success_by_type.index, success_by_type['mean'])
        plt.title('–£—Å–ø–µ—à–Ω–æ—Å—Ç—å –ø–æ —Ç–∏–ø–∞–º –∑–∞–¥–∞–Ω–∏–π')
        plt.ylabel('–î–æ–ª—è —É—Å–ø–µ—à–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫')
        plt.ylim(0, 1)
        for i, (bar, count) in enumerate(zip(bars, success_by_type['count'])):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                    f'{success_by_type["mean"].iloc[i]:.2f}\n({count:,})', 
                    ha='center', va='bottom')
        
        # 3. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–≥—Ä–∞–¥
        plt.subplot(4, 3, 3)
        plt.hist(df['total_reward'], bins=50, alpha=0.7, edgecolor='black')
        plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ–±—â–∏—Ö –Ω–∞–≥—Ä–∞–¥')
        plt.xlabel('–û–±—â–∞—è –Ω–∞–≥—Ä–∞–¥–∞')
        plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
        plt.axvline(df['total_reward'].mean(), color='red', linestyle='--', 
                   label=f'–°—Ä–µ–¥–Ω–µ–µ: {df["total_reward"].mean():.3f}')
        plt.legend()
          # 4. –ü–æ–∫—Ä—ã—Ç–∏–µ –Ω–∞–≤—ã–∫–æ–≤ –ø–æ —É—Ä–æ–≤–Ω—è–º
        plt.subplot(4, 3, 4)
        level_coverage = pd.Series(self.stats['level_coverage'])
        level_coverage = level_coverage.sort_index()
        bars = plt.bar(list(level_coverage.index), list(level_coverage.values))
        plt.title('–ü–æ–∫—Ä—ã—Ç–∏–µ –Ω–∞–≤—ã–∫–æ–≤ –ø–æ —É—Ä–æ–≤–Ω—è–º')
        plt.xlabel('–£—Ä–æ–≤–µ–Ω—å –Ω–∞–≤—ã–∫–∞')
        plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π')
        for bar, count in zip(bars, level_coverage.values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50, 
                    f'{count:,}', ha='center', va='bottom')
        
        # 5. –î–∏–Ω–∞–º–∏–∫–∞ –æ—Å–≤–æ–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤
        plt.subplot(4, 3, 5)
        # –ë–µ—Ä–µ–º —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å—Ç—É–¥–µ–Ω—Ç–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        sample_student = df[df['student_id'] == df['student_id'].iloc[0]].copy()
        sample_student = sample_student.reset_index(drop=True)
        plt.plot(sample_student.index, sample_student['current_skill_mastery'], 
                linewidth=2, marker='o', markersize=4)
        plt.title(f'–ü—Ä–∏–º–µ—Ä –æ—Å–≤–æ–µ–Ω–∏—è –Ω–∞–≤—ã–∫–∞ (—Å—Ç—É–¥–µ–Ω—Ç {sample_student["student_id"].iloc[0]})')
        plt.xlabel('–ù–æ–º–µ—Ä –ø–æ–ø—ã—Ç–∫–∏')
        plt.ylabel('–£—Ä–æ–≤–µ–Ω—å –æ—Å–≤–æ–µ–Ω–∏—è')
        plt.grid(True, alpha=0.3)
        
        # 6. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏ –Ω–∞–≥—Ä–∞–¥
        plt.subplot(4, 3, 6)
        reward_cols = ['immediate_reward', 'learning_reward', 'exploration_reward']
        reward_corr = df[reward_cols].corr()
        sns.heatmap(reward_corr, annot=True, cmap='coolwarm', center=0, 
                   square=True, cbar_kws={'shrink': 0.8})
        plt.title('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞–≥—Ä–∞–¥')
        
        # 7. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω —ç–ø–∏–∑–æ–¥–æ–≤
        plt.subplot(4, 3, 7)
        episode_lengths = df.groupby('student_id').size()
        plt.hist(episode_lengths, bins=30, alpha=0.7, edgecolor='black')
        plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω —ç–ø–∏–∑–æ–¥–æ–≤')
        plt.xlabel('–î–ª–∏–Ω–∞ —ç–ø–∏–∑–æ–¥–∞')
        plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤')
        plt.axvline(episode_lengths.mean(), color='red', linestyle='--', 
                   label=f'–°—Ä–µ–¥–Ω–µ–µ: {episode_lengths.mean():.1f}')
        plt.legend()
        
        # 8. –£—Å–ø–µ—à–Ω–æ—Å—Ç—å vs –æ—Å–≤–æ–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–∞
        plt.subplot(4, 3, 8)
        plt.scatter(df['current_skill_mastery'], df['target'], alpha=0.1, s=1)
        plt.title('–£—Å–ø–µ—à–Ω–æ—Å—Ç—å vs –û—Å–≤–æ–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–∞')
        plt.xlabel('–£—Ä–æ–≤–µ–Ω—å –æ—Å–≤–æ–µ–Ω–∏—è –Ω–∞–≤—ã–∫–∞')
        plt.ylabel('–£—Å–ø–µ—à–Ω–æ—Å—Ç—å (target)')
        # –î–æ–±–∞–≤–ª—è–µ–º –ª–∏–Ω–∏—é —Ç—Ä–µ–Ω–¥–∞
        z = np.polyfit(df['current_skill_mastery'], df['target'], 1)
        p = np.poly1d(z)
        plt.plot(df['current_skill_mastery'].unique(), 
                p(df['current_skill_mastery'].unique()), "r--", alpha=0.8)
        
        # 9. –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å —ç–∫—Å–ø–µ—Ä—Ç–∞
        plt.subplot(4, 3, 9)
        expert_feedback = df[df['expert_feedback'] != 0]['expert_feedback']
        if len(expert_feedback) > 0:
            plt.hist(expert_feedback, bins=20, alpha=0.7, edgecolor='black')
            plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏')
            plt.xlabel('–û—Ü–µ–Ω–∫–∞ —ç–∫—Å–ø–µ—Ä—Ç–∞')
            plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
            plt.axvline(expert_feedback.mean(), color='red', linestyle='--', 
                       label=f'–°—Ä–µ–¥–Ω–µ–µ: {expert_feedback.mean():.3f}')
            plt.legend()
        else:
            plt.text(0.5, 0.5, '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ–±\n—ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏', 
                    ha='center', va='center', transform=plt.gca().transAxes)
            plt.title('–≠–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å')
        
        # 10. –ü—Ä–æ–≥—Ä–µ—Å—Å–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        plt.subplot(4, 3, 10)
        # –°–æ–∑–¥–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∫ —á–∏—Å–ª–∞–º
        difficulty_map = {'beginner': 1, 'intermediate': 2, 'advanced': 3}
        sample_trajectory = df[df['student_id'] == df['student_id'].iloc[100]].copy()
        sample_trajectory = sample_trajectory.reset_index(drop=True)
        sample_trajectory['difficulty_num'] = sample_trajectory['difficulty'].map(difficulty_map)
        
        plt.plot(sample_trajectory.index, sample_trajectory['difficulty_num'], 
                linewidth=2, marker='s', markersize=4)
        plt.title(f'–ü—Ä–æ–≥—Ä–µ—Å—Å–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ (—Å—Ç—É–¥–µ–Ω—Ç {sample_trajectory["student_id"].iloc[0]})')
        plt.xlabel('–ù–æ–º–µ—Ä –ø–æ–ø—ã—Ç–∫–∏')
        plt.ylabel('–°–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞–Ω–∏—è')
        plt.yticks([1, 2, 3], ['Beginner', 'Intermediate', 'Advanced'])
        plt.grid(True, alpha=0.3)
          # 11. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫—É—Ä—Å–∞–º
        plt.subplot(4, 3, 11)
        course_stats = pd.Series(self.stats['course_coverage'])
        bars = plt.bar(range(len(course_stats)), list(course_stats.values))
        plt.title('–ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ –∫—É—Ä—Å–∞–º')
        plt.xlabel('ID –∫—É—Ä—Å–∞')
        plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π')
        plt.xticks(range(len(course_stats)), list(course_stats.index))
        for bar, count in zip(bars, course_stats.values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50, 
                    f'{count:,}', ha='center', va='bottom')
        
        # 12. –í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏
        plt.subplot(4, 3, 12)
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø–æ—Ä—è–¥–∫–æ–≤–æ–º—É –Ω–æ–º–µ—Ä—É –ø–æ–ø—ã—Ç–∫–∏ –≤ —ç–ø–∏–∑–æ–¥–µ
        df_with_attempt_num = df.copy()
        df_with_attempt_num['attempt_in_episode'] = df_with_attempt_num.groupby('student_id').cumcount()
        
        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 50 –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏
        temporal_success = df_with_attempt_num[df_with_attempt_num['attempt_in_episode'] < 50]
        temporal_success = temporal_success.groupby('attempt_in_episode')['target'].mean()
        
        plt.plot(list(temporal_success.index), list(temporal_success.values), linewidth=2, marker='o', markersize=3)
        plt.title('–î–∏–Ω–∞–º–∏–∫–∞ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ –≤ —ç–ø–∏–∑–æ–¥–µ')
        plt.xlabel('–ù–æ–º–µ—Ä –ø–æ–ø—ã—Ç–∫–∏ –≤ —ç–ø–∏–∑–æ–¥–µ')
        plt.ylabel('–°—Ä–µ–¥–Ω—è—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
        viz_file = self.output_path / "dkn_dataset_visualizations.png"
        plt.savefig(viz_file, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"   ‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {viz_file}")
        
        # –°–æ–∑–¥–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –¥–µ—Ç–∞–ª—å–Ω—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –≥—Ä–∞—Ñ–∞ –Ω–∞–≤—ã–∫–æ–≤
        self._create_skill_graph_visualization()
    
    def _create_skill_graph_visualization(self):
        """–°–æ–∑–¥–∞–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –≥—Ä–∞—Ñ–∞ –Ω–∞–≤—ã–∫–æ–≤"""
        try:
            import networkx as nx
            
            print(f"   üï∏Ô∏è  –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≥—Ä–∞—Ñ–∞ –Ω–∞–≤—ã–∫–æ–≤...")
            
            # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞—Ñ
            G = nx.DiGraph()
              # –î–æ–±–∞–≤–ª—è–µ–º —É–∑–ª—ã (–Ω–∞–≤—ã–∫–∏)
            for skill in self.skills.values():
                G.add_node(skill.id, 
                          name=skill.name, 
                          level=skill.level,
                          coverage=self.stats['skill_individual_coverage'].get(skill.id, 0))
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ä—ë–±—Ä–∞ (–ø—Ä–µ–¥–ø–æ—Å—ã–ª–∫–∏)
            for skill in self.skills.values():
                for prereq_id in skill.prerequisites:
                    if prereq_id in self.skills:
                        G.add_edge(prereq_id, skill.id)
            
            # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
            plt.figure(figsize=(16, 12))
            
            # –ü–æ–∑–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —É–∑–ª–æ–≤ –ø–æ —É—Ä–æ–≤–Ω—è–º
            pos = {}
            levels = defaultdict(list)
            for node, data in G.nodes(data=True):
                levels[data['level']].append(node)
            
            for level, nodes in levels.items():
                for i, node in enumerate(nodes):
                    pos[node] = (i - len(nodes)/2, -level)
            
            # –¶–≤–µ—Ç–∞ —É–∑–ª–æ–≤ –ø–æ –ø–æ–∫—Ä—ã—Ç–∏—é
            node_colors = []
            for node in G.nodes():
                coverage = G.nodes[node]['coverage']
                if coverage == 0:
                    node_colors.append('lightcoral')  # –ù–µ –ø–æ–∫—Ä—ã—Ç
                elif coverage < 1000:
                    node_colors.append('lightyellow')  # –ú–∞–ª–æ –ø–æ–∫—Ä—ã—Ç
                elif coverage < 5000:
                    node_colors.append('lightgreen')  # –•–æ—Ä–æ—à–æ –ø–æ–∫—Ä—ã—Ç
                else:
                    node_colors.append('darkgreen')  # –û—Ç–ª–∏—á–Ω–æ –ø–æ–∫—Ä—ã—Ç
            
            # –†–∏—Å—É–µ–º –≥—Ä–∞—Ñ
            nx.draw(G, pos, 
                   node_color=node_colors,
                   node_size=300,
                   with_labels=False,
                   arrows=True,
                   arrowsize=20,
                   edge_color='gray',
                   alpha=0.8)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å–∏ —É–∑–ª–æ–≤
            labels = {node: f"{data['name'][:15]}...\n({data['coverage']})" 
                     if len(data['name']) > 15 
                     else f"{data['name']}\n({data['coverage']})"
                     for node, data in G.nodes(data=True)}
            
            nx.draw_networkx_labels(G, pos, labels, font_size=6)
            
            plt.title('–ì—Ä–∞—Ñ –Ω–∞–≤—ã–∫–æ–≤ DKN\n(—á–∏—Å–ª–∞ –≤ —Å–∫–æ–±–∫–∞—Ö - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ)', 
                     fontsize=14, pad=20)
              # –õ–µ–≥–µ–Ω–¥–∞
            from matplotlib.patches import Rectangle
            legend_elements = [
                Rectangle((0,0),1,1, facecolor='lightcoral', label='–ù–µ –ø–æ–∫—Ä—ã—Ç (0)'),
                Rectangle((0,0),1,1, facecolor='lightyellow', label='–ú–∞–ª–æ (<1K)'),
                Rectangle((0,0),1,1, facecolor='lightgreen', label='–•–æ—Ä–æ—à–æ (1K-5K)'),
                Rectangle((0,0),1,1, facecolor='darkgreen', label='–û—Ç–ª–∏—á–Ω–æ (>5K)')
            ]
            plt.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.15, 1))
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            graph_file = self.output_path / "skill_graph_visualization.png"
            plt.savefig(graph_file, dpi=300, bbox_inches='tight', facecolor='white')
            plt.close()
            
            print(f"   ‚úÖ –ì—Ä–∞—Ñ –Ω–∞–≤—ã–∫–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {graph_file}")
            
        except ImportError:
            print(f"   ‚ö†Ô∏è  NetworkX –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –≥—Ä–∞—Ñ–∞")
        except Exception as e:
            print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≥—Ä–∞—Ñ–∞ –Ω–∞–≤—ã–∫–æ–≤: {e}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""
    print("ü§ñ –ì–ï–ù–ï–†–ê–¢–û–† DKN –î–ê–ù–ù–´–• –° –û–ë–£–ß–ï–ù–ò–ï–ú –° –ü–û–î–ö–†–ï–ü–õ–ï–ù–ò–ï–ú")
    print("=" * 70)
    
    # –°–æ–∑–¥–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä
    generator = DKNReinforcementDataGenerator(
        target_students=1500,
        output_path="dataset"
    )
    
    try:
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        df = generator.generate_full_dataset()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        generator.save_dataset(df)
        
        print(f"\nüéâ –ì–ï–ù–ï–†–ê–¶–ò–Ø –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–ê!")
        print(f"üìä –°–æ–∑–¥–∞–Ω–æ {len(df):,} –∑–∞–ø–∏—Å–µ–π –¥–ª—è {df['student_id'].nunique():,} —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
        print(f"üéØ –ü–æ–∫—Ä—ã—Ç–æ {len(generator.stats['skills_covered'])}/{len(generator.skills)} –Ω–∞–≤—ã–∫–æ–≤")
        print(f"üìà –û–±—â–∞—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å: {df['target'].mean()*100:.1f}%")
        print(f"üèÜ –°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞: {df['total_reward'].mean():.3f}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
