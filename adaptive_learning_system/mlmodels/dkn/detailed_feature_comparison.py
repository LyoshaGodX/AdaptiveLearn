#!/usr/bin/env python3
"""
–î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è DKN –º–æ–¥–µ–ª–∏

–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ç–æ—á–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–¥–∞—é—Ç—Å—è –≤ DKN –º–æ–¥–µ–ª—å:
1. –ò–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å—Ç—É–¥–µ–Ω—Ç–∞
2. –ò–∑ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–±—É—á–∞—é—â–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
"""

import os
import sys
import django
from pathlib import Path
import torch
import numpy as np
import pandas as pd
from typing import Dict, List, Any

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Django
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'adaptive_learning.settings')
django.setup()

from django.contrib.auth.models import User
from student.models import StudentProfile
from data_processor import DKNDataProcessor

# –ò–º–ø–æ—Ä—Ç custom_collate_fn –∏–∑ trainer –±–µ–∑ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞
def custom_collate_fn(batch_data):
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è collate_fn –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    # –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥—É–±–ª–∏—Ä—É–µ—Ç –ª–æ–≥–∏–∫—É –∏–∑ trainer.py –¥–ª—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
    
    if not batch_data:
        return {}
    
    batch_size = len(batch_data)
    num_skills = 30  # –ò–∑–≤–µ—Å—Ç–Ω–æ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    max_history = 10
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–Ω–∑–æ—Ä—ã
    skill_ids = torch.zeros((batch_size, num_skills), dtype=torch.long)
    bkt_params = torch.zeros((batch_size, num_skills, 4), dtype=torch.float32)
    task_ids = torch.zeros(batch_size, dtype=torch.long)
    task_difficulty = torch.zeros(batch_size, dtype=torch.long)
    task_type = torch.zeros(batch_size, dtype=torch.long)
    student_history = torch.zeros((batch_size, max_history, 10), dtype=torch.float32)
    current_bkt_avg = torch.zeros((batch_size, 4), dtype=torch.float32)
    skill_mask = torch.zeros((batch_size, num_skills), dtype=torch.float32)
    
    for i, sample in enumerate(batch_data):
        # –ó–∞–ø–æ–ª–Ω—è–µ–º skill_ids
        skill_ids[i] = torch.arange(num_skills)
        
        # BKT –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        bkt_data = sample.get('bkt_params', {})
        for skill_id, params in bkt_data.items():
            if skill_id < num_skills:
                bkt_params[i, skill_id] = torch.tensor([
                    params.get('P_L', 0.1),
                    params.get('P_T', 0.1), 
                    params.get('P_G', 0.1),
                    params.get('P_S', 0.1)
                ])
        
        # –ó–∞–¥–∞–Ω–∏–µ
        task_ids[i] = i  # –ü—Ä–æ—Å—Ç–æ–π –º–∞–ø–ø–∏–Ω–≥ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        task_data = sample.get('task_data', {})
        task_difficulty[i] = task_data.get('difficulty', 0)
        task_type[i] = task_data.get('task_type', 0)
        
        # –ò—Å—Ç–æ—Ä–∏—è
        history = sample.get('history', [])
        for j, hist_item in enumerate(history[:max_history]):
            if isinstance(hist_item, dict):
                student_history[i, j] = torch.tensor([
                    hist_item.get('task_id', 0),
                    hist_item.get('is_correct', 0),
                    hist_item.get('score', 0),
                    hist_item.get('time_spent', 0),
                    hist_item.get('difficulty', 0),
                    hist_item.get('task_type', 0),
                    0, 0, 0, 0  # –ó–∞–ø–æ–ª–Ω–∏—Ç–µ–ª–∏ –¥–ª—è –Ω–∞–≤—ã–∫–æ–≤
                ])
        
        # –°—Ä–µ–¥–Ω–∏–µ BKT
        if bkt_data:
            all_params = list(bkt_data.values())
            if all_params:
                current_bkt_avg[i] = torch.tensor([
                    np.mean([p.get('P_L', 0.1) for p in all_params]),
                    np.mean([p.get('P_T', 0.1) for p in all_params]),
                    np.mean([p.get('P_G', 0.1) for p in all_params]),
                    np.mean([p.get('P_S', 0.1) for p in all_params])
                ])
        
        # –ú–∞—Å–∫–∞ –Ω–∞–≤—ã–∫–æ–≤
        skill_mask[i] = 1.0  # –í—Å–µ –Ω–∞–≤—ã–∫–∏ –∞–∫—Ç–∏–≤–Ω—ã
    
    return {
        'skill_ids': skill_ids,
        'bkt_params': bkt_params,
        'task_ids': task_ids,
        'task_difficulty': task_difficulty,
        'task_type': task_type,
        'student_history': student_history,
        'current_bkt_avg': current_bkt_avg,
        'skill_mask': skill_mask
    }


def get_real_data_vectors(student_id: int = 7, num_tasks: int = 5):
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è DKN"""
    print(f"üîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (—Å—Ç—É–¥–µ–Ω—Ç ID={student_id})")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    processor = DKNDataProcessor(max_history_length=10)
    
    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–¥–∞–Ω–∏–π
    from methodist.models import Task
    test_tasks = Task.objects.all()[:num_tasks]
    
    student_data_list = []
    for task in test_tasks:
        try:
            student_data = processor.get_student_data(student_id, task.id)
            student_data_list.append(student_data)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–ª—è –∑–∞–¥–∞–Ω–∏—è {task.id}: {e}")
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –±–∞—Ç—á —á–µ—Ä–µ–∑ collate_fn
    if student_data_list:
        batch = custom_collate_fn(student_data_list)
        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –±–∞—Ç—á —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {len(student_data_list)} –æ–±—Ä–∞–∑—Ü–æ–≤")
        return batch, student_data_list
    
    return None, None


def get_synthetic_data_vectors(num_samples: int = 5):
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤–µ–∫—Ç–æ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è DKN"""
    print(f"üîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ({num_samples} –æ–±—Ä–∞–∑—Ü–æ–≤)")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
    synthetic_path = Path("dataset/enhanced_synthetic_dataset.csv")
    if not synthetic_path.exists():
        print(f"‚ùå –§–∞–π–ª {synthetic_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return None, None
    
    df = pd.read_csv(synthetic_path)
    
    # –ë–µ—Ä–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –æ–±—Ä–∞–∑—Ü—ã
    sample_df = df.sample(n=num_samples, random_state=42)
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è DKN (–∫–∞–∫ –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –ø–∞–π–ø–ª–∞–π–Ω–µ)
    synthetic_batch = []
    
    for _, row in sample_df.iterrows():
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ —Ç–æ–º –∂–µ —Ñ–æ—Ä–º–∞—Ç–µ, —á—Ç–æ –∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        
        # –ò—Å—Ç–æ—Ä–∏—è –ø–æ–ø—ã—Ç–æ–∫ (hist_0_correct, hist_0_score, hist_0_time, –∏ —Ç.–¥.)
        history = []
        for i in range(10):  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º max_history_length = 10
            if f'hist_{i}_correct' in row:
                hist_item = {
                    'is_correct': float(row[f'hist_{i}_correct']),
                    'score': float(row[f'hist_{i}_score']),
                    'time_spent': float(row[f'hist_{i}_time']),
                }
                history.append(hist_item)
        
        # BKT –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–∏—â–µ–º skill_*_learned, skill_*_transit –∏ —Ç.–¥.)
        bkt_params = {}
        skill_columns = [col for col in row.index if col.startswith('skill_')]
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –Ω–∞–≤—ã–∫–∞–º
        skills_found = set()
        for col in skill_columns:
            if '_learned' in col or '_transit' in col:
                skill_num = col.split('_')[1]
                skills_found.add(skill_num)
        
        for skill_num in skills_found:
            bkt_params[int(skill_num)] = {
                'P_L': float(row.get(f'skill_{skill_num}_learned', 0.1)),
                'P_T': float(row.get(f'skill_{skill_num}_transit', 0.1)),
                'P_G': 0.1,  # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –Ω–µ—Ç –≤ –¥–∞–Ω–Ω—ã—Ö
                'P_S': 0.1
            }
        
        # –î–∞–Ω–Ω—ã–µ –∑–∞–¥–∞–Ω–∏—è
        task_data = {
            'difficulty': int(row.get('task_difficulty', 0)),
            'task_type': int(row.get('task_type', 0)),
        }
        
        # –°–æ–±–∏—Ä–∞–µ–º –æ–±—Ä–∞–∑–µ—Ü
        sample = {
            'student_id': int(row['student_id']),
            'task_id': int(row['task_id']),
            'history': history,
            'bkt_params': bkt_params,
            'task_skills': [0],  # –£–ø—Ä–æ—â–µ–Ω–Ω–æ
            'task_data': task_data,
            'target': float(row['target'])
        }
        
        synthetic_batch.append(sample)
    
    print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω –±–∞—Ç—á —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {len(synthetic_batch)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    return synthetic_batch, sample_df


def compare_batch_structure(real_batch, synthetic_batch):
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –±–∞—Ç—á–µ–π"""
    print(f"\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –°–¢–†–£–ö–¢–£–†–´ –ë–ê–¢–ß–ï–ô")
    print("=" * 50)
    
    if real_batch is None or synthetic_batch is None:
        print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –±–∞—Ç—á–µ–π")
        return
    
    # –†–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (—É–∂–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Ç–µ–Ω–∑–æ—Ä–æ–≤ –æ—Ç collate_fn)
    print("üîç –†–µ–∞–ª—å–Ω—ã–π –±–∞—Ç—á (—Ç–µ–Ω–∑–æ—Ä—ã):")
    for key, tensor in real_batch.items():
        if isinstance(tensor, torch.Tensor):
            print(f"   {key}: {tensor.shape} ({tensor.dtype})")
        else:
            print(f"   {key}: {type(tensor)} - {len(tensor) if hasattr(tensor, '__len__') else 'N/A'}")
    
    # –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (–µ—â–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤–∞—Ä–µ–π)
    print(f"\nüîç –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –±–∞—Ç—á (raw data):")
    if synthetic_batch:
        sample = synthetic_batch[0]
        print(f"   –û–±—Ä–∞–∑—Ü–æ–≤: {len(synthetic_batch)}")
        print(f"   –ö–ª—é—á–∏ –æ–±—Ä–∞–∑—Ü–∞: {list(sample.keys())}")
        print(f"   –ò—Å—Ç–æ—Ä–∏—è: {len(sample['history'])} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
        print(f"   BKT –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: {len(sample['bkt_params'])} –Ω–∞–≤—ã–∫–æ–≤")
        print(f"   –ù–∞–≤—ã–∫–∏ –∑–∞–¥–∞–Ω–∏—è: {len(sample['task_skills'])}")


def compare_feature_values(real_batch, real_data, synthetic_batch, synthetic_df):
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    print(f"\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –ó–ù–ê–ß–ï–ù–ò–ô –ü–†–ò–ó–ù–ê–ö–û–í")
    print("=" * 50)
    
    # –ò—Å—Ç–æ—Ä–∏—è –ø–æ–ø—ã—Ç–æ–∫
    print("üìö –ò–°–¢–û–†–ò–Ø –ü–û–ü–´–¢–û–ö:")
    print("-" * 30)
    
    if real_batch and 'student_history' in real_batch:
        real_history = real_batch['student_history']
        print(f"üîç –†–µ–∞–ª—å–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è: {real_history.shape}")
        print(f"   –ó–Ω–∞—á–µ–Ω–∏—è: {real_history[0, :3, :3]}")  # –ü–µ—Ä–≤—ã–µ 3x3 –∑–Ω–∞—á–µ–Ω–∏—è
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –∏—Å—Ç–æ—Ä–∏–∏
        non_zero_mask = real_history != 0
        if non_zero_mask.any():
            print(f"   –ù–µ–Ω—É–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {non_zero_mask.sum().item()}")
            print(f"   –°—Ä–µ–¥–Ω–µ–µ (–Ω–µ–Ω—É–ª–µ–≤–æ–µ): {real_history[non_zero_mask].mean().item():.3f}")
    
    if synthetic_batch:
        print(f"\nüîç –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∞—è –∏—Å—Ç–æ—Ä–∏—è (–ø–µ—Ä–≤—ã–π –æ–±—Ä–∞–∑–µ—Ü):")
        hist = synthetic_batch[0]['history'][:3]  # –ü–µ—Ä–≤—ã–µ 3 —ç–ª–µ–º–µ–Ω—Ç–∞
        for i, h in enumerate(hist):
            print(f"   [{i}]: correct={h['is_correct']}, score={h['score']:.2f}, time={h['time_spent']:.1f}")
    
    # BKT –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    print(f"\nüìà BKT –ü–ê–†–ê–ú–ï–¢–†–´:")
    print("-" * 30)
    
    if real_batch and 'bkt_params' in real_batch:
        real_bkt = real_batch['bkt_params']
        print(f"üîç –†–µ–∞–ª—å–Ω—ã–µ BKT: {real_bkt.shape}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –ø–∞—Ä–∞–º–µ—Ç—Ä—É
        for i, param_name in enumerate(['P_L', 'P_T', 'P_G', 'P_S']):
            param_values = real_bkt[:, :, i]
            non_zero = param_values[param_values != 0]
            if len(non_zero) > 0:
                print(f"   {param_name}: {non_zero.mean():.3f} ¬± {non_zero.std():.3f} ({len(non_zero)} –Ω–µ–Ω—É–ª–µ–≤—ã—Ö)")
    
    if synthetic_batch:
        print(f"\nüîç –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ BKT (–ø–µ—Ä–≤—ã–π –æ–±—Ä–∞–∑–µ—Ü):")
        bkt = synthetic_batch[0]['bkt_params']
        for skill_id, params in list(bkt.items())[:3]:  # –ü–µ—Ä–≤—ã–µ 3 –Ω–∞–≤—ã–∫–∞
            print(f"   –ù–∞–≤—ã–∫ {skill_id}: P_L={params['P_L']:.3f}, P_T={params['P_T']:.3f}")
    
    # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∑–∞–¥–∞–Ω–∏–π
    print(f"\nüìù –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò –ó–ê–î–ê–ù–ò–ô:")
    print("-" * 30)
    
    if real_batch:
        if 'task_difficulty' in real_batch:
            real_diff = real_batch['task_difficulty']
            print(f"üîç –†–µ–∞–ª—å–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å: {real_diff}")
        if 'task_type' in real_batch:
            real_type = real_batch['task_type']
            print(f"üîç –†–µ–∞–ª—å–Ω—ã–π —Ç–∏–ø: {real_type}")
    
    if synthetic_batch:
        print(f"üîç –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏:")
        difficulties = [s['task_data']['difficulty'] for s in synthetic_batch]
        task_types = [s['task_data']['task_type'] for s in synthetic_batch]
        print(f"   –°–ª–æ–∂–Ω–æ—Å—Ç–∏: {difficulties}")
        print(f"   –¢–∏–ø—ã: {task_types}")


def compare_distributions(real_batch, synthetic_df):
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    print(f"\nüìä –°–†–ê–í–ù–ï–ù–ò–ï –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ô")
    print("=" * 50)
    
    # –£—Å–ø–µ—à–Ω–æ—Å—Ç—å (—Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è)
    print("üéØ –¶–ï–õ–ï–í–ê–Ø –ü–ï–†–ï–ú–ï–ù–ù–ê–Ø (—É—Å–ø–µ—à–Ω–æ—Å—Ç—å):")
    
    if synthetic_df is not None and 'target' in synthetic_df.columns:
        synthetic_success_rate = synthetic_df['target'].mean()
        synthetic_std = synthetic_df['target'].std()
        print(f"   –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ: {synthetic_success_rate:.3f} ¬± {synthetic_std:.3f}")
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≥—Ä—É–ø–ø–∞–º
        print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:")
        print(f"     0 (–Ω–µ—É—Å–ø–µ—Ö): {(synthetic_df['target'] == 0).sum()} ({(synthetic_df['target'] == 0).mean():.1%})")
        print(f"     1 (—É—Å–ø–µ—Ö): {(synthetic_df['target'] == 1).sum()} ({(synthetic_df['target'] == 1).mean():.1%})")
    
    # –í—Ä–µ–º—è —Ä–µ—à–µ–Ω–∏—è
    print(f"\n‚è±Ô∏è –í–†–ï–ú–Ø –†–ï–®–ï–ù–ò–Ø:")
    
    if synthetic_df is not None:
        time_columns = [col for col in synthetic_df.columns if 'time' in col]
        if time_columns:
            sample_time_col = time_columns[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –∫–æ–ª–æ–Ω–∫—É –≤—Ä–µ–º–µ–Ω–∏
            times = synthetic_df[sample_time_col].dropna()
            if len(times) > 0:
                print(f"   –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–µ –≤—Ä–µ–º—è ({sample_time_col}):")
                print(f"     –°—Ä–µ–¥–Ω–µ–µ: {times.mean():.1f}—Å")
                print(f"     –ú–µ–¥–∏–∞–Ω–∞: {times.median():.1f}—Å")
                print(f"     –î–∏–∞–ø–∞–∑–æ–Ω: {times.min():.1f} - {times.max():.1f}—Å")


def generate_feature_comparison_report(real_batch, synthetic_batch):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
    print(f"\nüìã –û–¢–ß–ï–¢ –°–†–ê–í–ù–ï–ù–ò–Ø –í–ï–ö–¢–û–†–û–í –ü–†–ò–ó–ù–ê–ö–û–í")
    print("=" * 60)
    
    print("üéØ –ö–õ–Æ–ß–ï–í–´–ï –ù–ê–•–û–î–ö–ò:")
    print("-" * 40)
    
    # –°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–æ–≤
    print("‚úÖ –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨ –§–û–†–ú–ê–¢–û–í:")
    if real_batch and synthetic_batch:
        print("   ‚úì –†–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É—é—Ç—Å—è –≤ —Ç–µ–Ω–∑–æ—Ä—ã")
        print("   ‚úì –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∏–º–µ—é—Ç —Ç—É –∂–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É")
        print("   ‚úì –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º—ã —Å DKN –º–æ–¥–µ–ª—å—é")
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–∞–∑–ª–∏—á–∏—è
    print(f"\nüîÑ –û–°–ù–û–í–ù–´–ï –†–ê–ó–õ–ò–ß–ò–Ø:")
    print("   üìä –†–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:")
    print("     - –û—Å–Ω–æ–≤–∞–Ω—ã –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–æ–ø—ã—Ç–∫–∞—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
    print("     - BKT –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—ã—á–∏—Å–ª–µ–Ω—ã –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏")
    print("     - –û–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π")
    print("     - –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø–æ–≤–µ–¥–µ–Ω–∏—è")
    
    print("   üé≤ –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ:")
    print("     - –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –º–æ–¥–µ–ª—è–º –ø–æ–≤–µ–¥–µ–Ω–∏—è")
    print("     - –ü–æ–ª–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    print("     - –ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ–º—ã–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è")
    print("     - –ë–æ–ª—å—à–æ–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤")
    
    # –í—ã–≤–æ–¥—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    print(f"\nüí° –í–´–í–û–î–´ –î–õ–Ø –û–ë–£–ß–ï–ù–ò–Ø DKN:")
    print("   1. –°–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –ª—É—á—à–µ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ")
    print("   2. –†–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω—É–∂–Ω—ã –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∏ fine-tuning")
    print("   3. –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –ø–µ—Ä–µ–∫–ª—é—á–∞—Ç—å—Å—è –º–µ–∂–¥—É —Ç–∏–ø–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö")
    print("   4. –í–∞–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç—å BKT –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è"""
    print("üîç –î–ï–¢–ê–õ–¨–ù–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –í–ï–ö–¢–û–†–û–í –ü–†–ò–ó–ù–ê–ö–û–í DKN")
    print("=" * 70)
    
    try:
        # 1. –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        real_batch, real_data = get_real_data_vectors(student_id=7, num_tasks=5)
        
        # 2. –ü–æ–ª—É—á–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤–µ–∫—Ç–æ—Ä—ã –ø—Ä–∏–∑–Ω–∞–∫–æ–≤  
        synthetic_batch, synthetic_df = get_synthetic_data_vectors(num_samples=5)
        
        # 3. –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –±–∞—Ç—á–µ–π
        compare_batch_structure(real_batch, synthetic_batch)
        
        # 4. –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        compare_feature_values(real_batch, real_data, synthetic_batch, synthetic_df)
        
        # 5. –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        compare_distributions(real_batch, synthetic_df)
        
        # 6. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        generate_feature_comparison_report(real_batch, synthetic_batch)
        
        print(f"\nüéâ –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        
    except Exception as e:
        print(f"üí• –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
