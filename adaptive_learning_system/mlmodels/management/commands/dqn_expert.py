"""
Django –∫–æ–º–∞–Ω–¥–∞ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é DQN

–ü–æ–∑–≤–æ–ª—è–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç–∞–º:
- –ü—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
- –î–æ–±–∞–≤–ª—è—Ç—å –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å (–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—É—é/–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—É—é)
- –ó–∞–ø—É—Å–∫–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
- –ü—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è
"""

from django.core.management.base import BaseCommand, CommandError
from django.utils import timezone
from datetime import datetime, timedelta

from mlmodels.dqn.recommendation_manager_fixed import recommendation_manager_fixed as recommendation_manager
from mlmodels.dqn.expert_feedback_manager import expert_feedback_manager
from mlmodels.models import DQNRecommendation, ExpertFeedback
from student.models import StudentProfile


class Command(BaseCommand):
    help = '–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å —ç–∫—Å–ø–µ—Ä—Ç–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å DQN –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é'
    
    def add_arguments(self, parser):
        parser.add_argument(
            'action',
            choices=['history', 'feedback', 'train', 'stats'],
            help='–î–µ–π—Å—Ç–≤–∏–µ: history (–∏—Å—Ç–æ—Ä–∏—è), feedback (–æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å), train (–æ–±—É—á–µ–Ω–∏–µ), stats (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)'
        )
        
        parser.add_argument(
            '--student',
            type=int,
            help='ID —Å—Ç—É–¥–µ–Ω—Ç–∞ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏—Å—Ç–æ—Ä–∏–∏'
        )
        
        parser.add_argument(
            '--recommendation',
            type=int,
            help='ID —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏'
        )
        
        parser.add_argument(
            '--expert',
            type=int,
            default=1,
            help='ID —ç–∫—Å–ø–µ—Ä—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1)'
        )
        
        parser.add_argument(
            '--feedback-type',
            choices=['positive', 'negative'],
            help='–¢–∏–ø –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏'
        )
        
        parser.add_argument(
            '--strength',
            choices=['low', 'medium', 'strong'],
            default='medium',
            help='–°–∏–ª–∞ –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é medium)'
        )
        
        parser.add_argument(
            '--comment',
            type=str,
            default='',
            help='–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∫ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏'
        )
        
        parser.add_argument(
            '--limit',
            type=int,
            default=20,
            help='–õ–∏–º–∏—Ç –∑–∞–ø–∏—Å–µ–π –¥–ª—è –≤—ã–≤–æ–¥–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 20)'
        )
        
        parser.add_argument(
            '--days',
            type=int,
            default=30,
            help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 30)'
        )
    
    def handle(self, *args, **options):
        action = options['action']
        
        try:
            if action == 'history':
                self._show_recommendation_history(options)
            elif action == 'feedback':
                self._add_expert_feedback(options)
            elif action == 'train':
                self._train_model(options)
            elif action == 'stats':
                self._show_statistics(options)
            
        except Exception as e:
            raise CommandError(f'–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã: {e}')
    
    def _show_recommendation_history(self, options):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        student_id = options.get('student')
        limit = options.get('limit', 20)
        
        if not student_id:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—Å–µ–º —Å—Ç—É–¥–µ–Ω—Ç–∞–º
            self.stdout.write(
                self.style.SUCCESS('üìö –û–ë–©–ê–Ø –ò–°–¢–û–†–ò–Ø –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ô')
            )
            self.stdout.write('=' * 60)
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendations = DQNRecommendation.objects.select_related(
                'student', 'task'
            ).prefetch_related(
                'expertfeedback_set'            ).order_by('-created_at')[:limit]
            
            for i, rec in enumerate(recommendations, 1):
                feedback = rec.expertfeedback_set.first()
                feedback_info = ""
                
                if feedback:
                    feedback_type = "‚úÖ" if feedback.feedback_type == 'positive' else "‚ùå"
                    feedback_info = f" | {feedback_type} {feedback.strength} ({feedback.reward_value:+.1f})"
                
                self.stdout.write(
                    f"{i:2d}. –°—Ç—É–¥–µ–Ω—Ç {rec.student.id} | "
                    f"–ó–∞–¥–∞–Ω–∏–µ {rec.task.id} | "
                    f"Q={rec.q_value:.3f} | "
                    f"{rec.created_at.strftime('%Y-%m-%d %H:%M')}"
                    f"{feedback_info}"
                )
            
        else:
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å—Ç—É–¥–µ–Ω—Ç–∞
            try:
                student = StudentProfile.objects.get(id=student_id)
            except StudentProfile.DoesNotExist:
                raise CommandError(f'–°—Ç—É–¥–µ–Ω—Ç —Å ID {student_id} –Ω–µ –Ω–∞–π–¥–µ–Ω')
            
            self.stdout.write(
                self.style.SUCCESS(f'üìö –ò–°–¢–û–†–ò–Ø –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ô –î–õ–Ø –°–¢–£–î–ï–ù–¢–ê {student_id}')
            )
            self.stdout.write('=' * 60)
            
            history = recommendation_manager.get_recommendation_history(
                student_id, limit=limit
            )
            
            if not history:
                self.stdout.write(
                    self.style.WARNING('–ù–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Å—Ç—É–¥–µ–Ω—Ç–∞')
                )
                return
            
            for i, rec in enumerate(history, 1):
                attempts_info = ""
                if rec['has_attempts']:
                    attempts_info = f" | –ü–æ–ø—ã—Ç–æ–∫: {len(rec['attempts'])}, –£—Å–ø–µ—Ö: {rec['success_rate']:.1%}"
                
                self.stdout.write(
                    f"{i:2d}. [{rec['id']}] {rec['task_title']} | "
                    f"Q={rec['q_value']:.3f} | "
                    f"{rec['difficulty']} | "
                    f"{rec['created_at'].strftime('%Y-%m-%d %H:%M')}"
                    f"{attempts_info}"
                )
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –µ—Å–ª–∏ –µ—Å—Ç—å
                try:
                    feedback = ExpertFeedback.objects.get(recommendation_id=rec['id'])
                    feedback_type = "‚úÖ –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è" if feedback.feedback_type == 'positive' else "‚ùå –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è"
                    self.stdout.write(
                        f"    üí¨ {feedback_type} ({feedback.strength}) = {feedback.reward_value:+.1f}"
                    )
                    if feedback.comment:
                        self.stdout.write(f"    üìù {feedback.comment}")
                except ExpertFeedback.DoesNotExist:
                    self.stdout.write("    ‚ö™ –ù–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏")
    
    def _add_expert_feedback(self, options):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç–Ω—É—é –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å"""
        recommendation_id = options.get('recommendation')
        expert_id = options.get('expert')
        feedback_type = options.get('feedback_type')
        strength = options.get('strength')
        comment = options.get('comment', '')
        
        if not recommendation_id:
            raise CommandError('–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å --recommendation')
        
        if not feedback_type:
            raise CommandError('–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å --feedback-type (positive/negative)')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        try:
            recommendation = DQNRecommendation.objects.select_related(
                'student', 'task'
            ).get(id=recommendation_id)
        except DQNRecommendation.DoesNotExist:
            raise CommandError(f'–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è —Å ID {recommendation_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞')
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        self.stdout.write(
            self.style.SUCCESS(f'üí¨ –î–û–ë–ê–í–õ–ï–ù–ò–ï –û–ë–†–ê–¢–ù–û–ô –°–í–Ø–ó–ò')
        )
        self.stdout.write('=' * 60)
        self.stdout.write(f"–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {recommendation.id}")
        self.stdout.write(f"–°—Ç—É–¥–µ–Ω—Ç: {recommendation.student.id}")
        self.stdout.write(f"–ó–∞–¥–∞–Ω–∏–µ: {recommendation.task.title}")
        self.stdout.write(f"Q-value: {recommendation.q_value:.4f}")
        self.stdout.write(f"–î–∞—Ç–∞: {recommendation.created_at.strftime('%Y-%m-%d %H:%M:%S')}")
        self.stdout.write('-' * 60)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å
        success = expert_feedback_manager.add_feedback(
            recommendation_id=recommendation_id,
            expert_id=expert_id,
            feedback_type=feedback_type,
            strength=strength,
            comment=comment
        )
        
        if success:
            reward = expert_feedback_manager.REWARD_MAPPING[strength][feedback_type]
            feedback_emoji = "‚úÖ" if feedback_type == 'positive' else "‚ùå"
            
            self.stdout.write(
                self.style.SUCCESS(
                    f'{feedback_emoji} –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –¥–æ–±–∞–≤–ª–µ–Ω–∞: {feedback_type} ({strength}) = {reward:+.1f}'
                )
            )
            if comment:
                self.stdout.write(f"üìù –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: {comment}")
        else:
            self.stdout.write(
                self.style.ERROR('‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å')
            )
    
    def _train_model(self, options):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        self.stdout.write(
            self.style.SUCCESS('üöÄ –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò DQN –ù–ê –≠–ö–°–ü–ï–†–¢–ù–û–ô –û–ë–†–ê–¢–ù–û–ô –°–í–Ø–ó–ò')
        )
        self.stdout.write('=' * 60)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        self.stdout.write("üìö –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
        training_data = expert_feedback_manager.prepare_training_data(min_feedback_count=3)
        
        if not training_data:
            self.stdout.write(
                self.style.WARNING('‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–º–∏–Ω–∏–º—É–º 3 –∑–∞–ø–∏—Å–∏ —Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é)')
            )
            return
        
        self.stdout.write(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(training_data)} –æ–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –¥–∞–Ω–Ω—ã—Ö
        positive_count = sum(1 for ex in training_data if ex['feedback_type'] == 'positive')
        negative_count = len(training_data) - positive_count
        avg_reward = sum(ex['reward'] for ex in training_data) / len(training_data)
        
        self.stdout.write(f"   - –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö: {positive_count}")
        self.stdout.write(f"   - –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö: {negative_count}")
        self.stdout.write(f"   - –°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞: {avg_reward:.3f}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ
        self.stdout.write("\nüéØ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è...")
        model_path = expert_feedback_manager.train_model_with_feedback(
            training_examples=training_data,
            learning_rate=1e-4,
            batch_size=min(16, len(training_data)),
            epochs=50
        )
        
        if model_path:
            self.stdout.write(
                self.style.SUCCESS(f'‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}')
            )
        else:
            self.stdout.write(
                self.style.ERROR('‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏')
            )
    
    def _show_statistics(self, options):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        days = options.get('days', 30)
        
        self.stdout.write(
            self.style.SUCCESS(f'üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê DQN –ó–ê –ü–û–°–õ–ï–î–ù–ò–ï {days} –î–ù–ï–ô')
        )
        self.stdout.write('=' * 60)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
        stats = expert_feedback_manager.get_feedback_stats(days=days)
        
        self.stdout.write("üí¨ –≠–∫—Å–ø–µ—Ä—Ç–Ω–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å:")
        self.stdout.write(f"   - –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {stats.total_feedback}")
        self.stdout.write(f"   - –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö: {stats.positive_feedback}")
        self.stdout.write(f"   - –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö: {stats.negative_feedback}")
        self.stdout.write(f"   - –°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞: {stats.avg_reward:.3f}")
        
        if stats.by_strength:
            self.stdout.write("   - –ü–æ —Å–∏–ª–µ –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏—è:")
            for strength, count in stats.by_strength.items():
                self.stdout.write(f"     ‚Ä¢ {strength}: {count}")
        
        if stats.by_expert:
            self.stdout.write("   - –ü–æ —ç–∫—Å–ø–µ—Ä—Ç–∞–º:")
            for expert_id, count in stats.by_expert.items():
                self.stdout.write(f"     ‚Ä¢ –≠–∫—Å–ø–µ—Ä—Ç {expert_id}: {count}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        since_date = timezone.now() - timedelta(days=days)
        total_recommendations = DQNRecommendation.objects.filter(
            created_at__gte=since_date
        ).count()
        
        recommendations_with_feedback = DQNRecommendation.objects.filter(
            created_at__gte=since_date,
            expertfeedback__isnull=False
        ).distinct().count()
        
        self.stdout.write(f"\nüéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        self.stdout.write(f"   - –í—Å–µ–≥–æ —Å–æ–∑–¥–∞–Ω–æ: {total_recommendations}")
        self.stdout.write(f"   - –° –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é: {recommendations_with_feedback}")
        
        if total_recommendations > 0:
            feedback_rate = recommendations_with_feedback / total_recommendations * 100
            self.stdout.write(f"   - –ü–æ–∫—Ä—ã—Ç–∏–µ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é: {feedback_rate:.1f}%")
        
        # –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        training_history = expert_feedback_manager.get_training_history(limit=5)
        
        self.stdout.write(f"\nü§ñ –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 5):")
        if not training_history:
            self.stdout.write("   - –ù–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π –æ–±—É—á–µ–Ω–∏—è")
        else:
            for session in training_history:
                status_emoji = "‚úÖ" if session['status'] == 'completed' else "‚ùå" if session['status'] == 'failed' else "‚è≥"
                self.stdout.write(
                    f"   {status_emoji} –°–µ—Å—Å–∏—è {session['id']}: "
                    f"{session['training_examples_count']} –ø—Ä–∏–º–µ—Ä–æ–≤, "
                    f"{session['epochs']} —ç–ø–æ—Ö"
                )
                if session['final_loss']:
                    self.stdout.write(f"      –§–∏–Ω–∞–ª—å–Ω–∞—è –ø–æ—Ç–µ—Ä—è: {session['final_loss']:.4f}")
