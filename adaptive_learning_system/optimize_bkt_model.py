"""
–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ BKT –º–æ–¥–µ–ª–∏ –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
–û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å –º–µ—Ç–æ–¥–æ–º EM –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
"""

import os
import sys
import django
from pathlib import Path

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Django
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'adaptive_learning.settings')
django.setup()

import pandas as pd
import numpy as np
import json
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import pickle
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, log_loss

from mlmodels.bkt.base_model import BKTModel, BKTParameters, TaskCharacteristics
from mlmodels.bkt.trainer import BKTTrainer, TrainingData
from skills.models import Course, Skill
from methodist.models import Task

class BKTOptimizer:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ BKT –º–æ–¥–µ–ª–∏"""
    
    def __init__(self, dataset_path: str = "bkt_training_data/bkt_training_dataset.csv"):
        self.dataset_path = dataset_path
        self.bkt_model = BKTModel()
        self.trainer = BKTTrainer(self.bkt_model)
        
        print("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞ BKT –º–æ–¥–µ–ª–∏")
        print(f"üìÇ –î–∞—Ç–∞—Å–µ—Ç: {dataset_path}")
    
    def load_dataset(self) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
        
        df = pd.read_csv(self.dataset_path)
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")
        print(f"   üë• –°—Ç—É–¥–µ–Ω—Ç–æ–≤: {df['student_id'].nunique()}")
        print(f"   üìù –ó–∞–¥–∞–Ω–∏–π: {df['task_id'].nunique()}")
        print(f"   üéØ –ù–∞–≤—ã–∫–æ–≤: {df['skill_id'].nunique()}")
        print(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {df['is_correct'].mean():.1%}")
        
        return df
    
    def prepare_training_data(self, df: pd.DataFrame) -> Tuple[List[Dict], List[Dict]]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è BKT"""
        print("üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Å—Ç—É–¥–µ–Ω—Ç—É –∏ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        df_sorted = df.sort_values(['student_id', 'timestamp'])
        
        training_examples = []
        validation_examples = []
        
        # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Å—Ç—É–¥–µ–Ω—Ç–∞–º –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ (80%) –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é (20%)
        students = df['student_id'].unique()
        train_students, val_students = train_test_split(
            students, test_size=0.2, random_state=42
        )
          # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        for student_id in train_students:
            student_data = df_sorted[df_sorted['student_id'] == student_id]
            
            for _, row in student_data.iterrows():
                example = TrainingData(
                    student_id=int(row['student_id']),
                    skill_id=int(row['skill_id']),
                    is_correct=bool(row['is_correct']),
                    task_id=int(row['task_id']),
                    timestamp=row['timestamp']
                )
                training_examples.append(example)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        for student_id in val_students:
            student_data = df_sorted[df_sorted['student_id'] == student_id]
            
            for _, row in student_data.iterrows():
                example = TrainingData(
                    student_id=int(row['student_id']),
                    skill_id=int(row['skill_id']),
                    is_correct=bool(row['is_correct']),
                    task_id=int(row['task_id']),
                    timestamp=row['timestamp']
                )
                validation_examples.append(example)
        
        print(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ:")
        print(f"   üéì –û–±—É—á–∞—é—â–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {len(training_examples)}")
        print(f"   üìã –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {len(validation_examples)}")
        print(f"   üë• –°—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ –æ–±—É—á–µ–Ω–∏–∏: {len(train_students)}")
        print(f"   üë• –°—Ç—É–¥–µ–Ω—Ç–æ–≤ –≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {len(val_students)}")
        
        return training_examples, validation_examples
    
    def load_skills_graph(self) -> Dict[int, List[int]]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –≥—Ä–∞—Ñ –Ω–∞–≤—ã–∫–æ–≤ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        print("üîó –ó–∞–≥—Ä—É–∑–∫–∞ –≥—Ä–∞—Ñ–∞ –Ω–∞–≤—ã–∫–æ–≤...")
        
        skills_graph = {}
        skills = Skill.objects.all()
        
        for skill in skills:
            prerequisites = list(skill.prerequisites.values_list('id', flat=True))
            skills_graph[skill.id] = prerequisites
            
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω –≥—Ä–∞—Ñ –∏–∑ {len(skills_graph)} –Ω–∞–≤—ã–∫–æ–≤")
        edges_count = sum(len(prereqs) for prereqs in skills_graph.values())
        print(f"   üîó –°–≤—è–∑–µ–π (–ø—Ä–µ—Ä–µ–∫–≤–∏–∑–∏—Ç–æ–≤): {edges_count}")
        
        return skills_graph
    
    def initialize_model_parameters(self, training_data: List[Dict]) -> Dict[int, BKTParameters]:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–∞–≤—ã–∫–∞"""
        print("‚öôÔ∏è –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏...")
          # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏ –∏–∑ –¥–∞–Ω–Ω—ã—Ö
        unique_skills = set(example.skill_id for example in training_data)
        
        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
        base_parameters = {
            'default': BKTParameters(P_L0=0.1, P_T=0.3, P_G=0.2, P_S=0.1)
        }
        
        skill_parameters = {}
        for skill_id in unique_skills:
            skill_parameters[skill_id] = base_parameters['default']
        
        print(f"‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è {len(skill_parameters)} –Ω–∞–≤—ã–∫–æ–≤")
        return skill_parameters
    
    def train_model(self, training_data: List[Dict], validation_data: List[Dict]) -> Dict:
        """–û–±—É—á–∏—Ç—å BKT –º–æ–¥–µ–ª—å –º–µ—Ç–æ–¥–æ–º EM"""
        print("üéØ –û–ë–£–ß–ï–ù–ò–ï BKT –ú–û–î–ï–õ–ò")
        print("=" * 50)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        skill_parameters = self.initialize_model_parameters(training_data)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≥—Ä–∞—Ñ –Ω–∞–≤—ã–∫–æ–≤
        skills_graph = self.load_skills_graph()
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å
        for skill_id, params in skill_parameters.items():
            self.bkt_model.set_skill_parameters(skill_id, params)
        
        self.bkt_model.set_skills_graph(skills_graph)
          # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        print("üîÑ –ó–∞–ø—É—Å–∫ EM –∞–ª–≥–æ—Ä–∏—Ç–º–∞...")
        training_results = self.trainer.train_with_em(
            training_data,
            max_iterations=20,
            tolerance=1e-4,
            verbose=True
        )
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        print("\nüìä –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        validation_results = self.validate_model(validation_data)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = {
            'training': training_results,
            'validation': validation_results,
            'model_parameters': self.get_model_parameters(),
            'training_timestamp': datetime.now().isoformat()        }
        
        return results
    
    def validate_model(self, validation_data: List[Dict]) -> Dict:
        """–í–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        predictions = []
        actual = []
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤
        student_ids = set(example.student_id for example in validation_data)
        skill_ids = list(self.bkt_model.skill_parameters.keys())
        
        for student_id in student_ids:
            self.bkt_model.initialize_student_all_skills(student_id, skill_ids)
        
        for example in validation_data:
            student_id = example.student_id
            skill_id = example.skill_id
            is_correct = example.is_correct
            
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            prediction = self.bkt_model.get_student_mastery(student_id, skill_id)
            predictions.append(prediction)
            actual.append(1.0 if is_correct else 0.0)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å—Ç—É–¥–µ–Ω—Ç–∞
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–¥–∞–Ω–∏—è, –ø–æ—Å–∫–æ–ª—å–∫—É —É –Ω–∞—Å –Ω–µ—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            task_chars = TaskCharacteristics(task_type="single_choice", difficulty="medium")
            answer_score = 1.0 if is_correct else 0.0
            self.bkt_model.update_student_state(
                student_id, skill_id, answer_score, task_chars
            )
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        # –î–ª—è accuracy –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ –±–∏–Ω–∞—Ä–Ω—ã–µ (> 0.5)
        binary_predictions = [1 if p > 0.5 else 0 for p in predictions]
        binary_actual = [1 if a > 0.5 else 0 for a in actual]
        
        accuracy = accuracy_score(binary_actual, binary_predictions)
        
        # –î–ª—è log-loss –Ω—É–∂–Ω—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å log(0)
        clipped_predictions = [max(min(p, 0.999), 0.001) for p in predictions]
        logloss = log_loss(binary_actual, clipped_predictions)
        
        validation_results = {
            'accuracy': float(accuracy),
            'log_loss': float(logloss),
            'num_examples': len(validation_data),
            'mean_prediction': float(np.mean(predictions)),
            'mean_actual': float(np.mean(actual))
        }
        
        print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏:")
        print(f"   üéØ –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.3f}")
        print(f"   üìä Log-loss: {logloss:.3f}")
        print(f"   üìù –ü—Ä–∏–º–µ—Ä–æ–≤: {len(validation_data)}")
        
        return validation_results
    
    def get_model_parameters(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏"""
        parameters = {}
        
        for skill_id, params in self.bkt_model.skill_parameters.items():
            parameters[skill_id] = {
                'P_L0': float(params.P_L0),
                'P_T': float(params.P_T),
                'P_G': float(params.P_G),
                'P_S': float(params.P_S)
            }
        
        return parameters
    
    def save_model(self, results: Dict, output_dir: str = "optimized_bkt_model") -> Dict[str, str]:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏...")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        files_created = {}
        
        # 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –≤ JSON
        model_data = {
            'skill_parameters': results['model_parameters'],
            'skills_graph': self.bkt_model.skills_graph,
            'training_results': results['training'],
            'validation_results': results['validation'],
            'metadata': {
                'training_timestamp': results['training_timestamp'],
                'model_type': 'BKT',
                'optimization_method': 'EM',
                'num_skills': len(results['model_parameters'])
            }
        }
        
        json_path = output_path / "bkt_model_optimized.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(model_data, f, indent=2, ensure_ascii=False)
        files_created['model_json'] = str(json_path)
        
        # 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å –≤ pickle –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        pickle_path = output_path / "bkt_model_optimized.pkl"
        with open(pickle_path, 'wb') as f:
            pickle.dump(self.bkt_model, f)
        files_created['model_pickle'] = str(pickle_path)
        
        # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
        results_path = output_path / "training_results.json"
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        files_created['results'] = str(results_path)
        
        # 4. –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
        report = self.generate_training_report(results)
        report_path = output_path / "TRAINING_REPORT.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        files_created['report'] = str(report_path)
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {len(files_created)} —Ñ–∞–π–ª–∞—Ö:")
        for file_type, file_path in files_created.items():
            print(f"   {file_type.upper()}: {file_path}")
        
        return files_created
    
    def generate_training_report(self, results: Dict) -> str:
        """–°–æ–∑–¥–∞—Ç—å –æ—Ç—á–µ—Ç –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –æ–±—É—á–µ–Ω–∏—è"""
        training_results = results['training']
        validation_results = results['validation']
        model_params = results['model_parameters']
        
        report = f"""# üéì –û–¢–ß–ï–¢ –û–ë –û–ë–£–ß–ï–ù–ò–ò BKT –ú–û–î–ï–õ–ò

**–î–∞—Ç–∞ –æ–±—É—á–µ–Ω–∏—è**: {results['training_timestamp']}
**–ú–µ—Ç–æ–¥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏**: Expectation-Maximization (EM)

---

## üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–£–ß–ï–ù–ò–Ø

### –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏:
- **–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏**: {validation_results['accuracy']:.3f}
- **Log-loss –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏**: {validation_results['log_loss']:.3f}
- **–û–±—É—á–µ–Ω–æ –Ω–∞–≤—ã–∫–æ–≤**: {len(model_params)}
- **–ò—Ç–µ—Ä–∞—Ü–∏–π EM**: {training_results.get('total_iterations', 'N/A')}
- **–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è**: {training_results.get('training_time_seconds', 'N/A')} —Å–µ–∫

### –°—Ö–æ–¥–∏–º–æ—Å—Ç—å:
- **–î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å**: {training_results.get('converged', 'N/A')}
- **–§–∏–Ω–∞–ª—å–Ω–∞—è log-likelihood**: {training_results.get('final_log_likelihood', 'N/A')}

---

## üéØ –ü–ê–†–ê–ú–ï–¢–†–´ –ù–ê–í–´–ö–û–í (—Ç–æ–ø-10 –ø–æ P_T)

"""
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞–≤—ã–∫–∏ –ø–æ P_T –¥–ª—è –ø–æ–∫–∞–∑–∞ —Å–∞–º—ã—Ö "–æ–±—É—á–∞–µ–º—ã—Ö"
        sorted_skills = sorted(
            model_params.items(), 
            key=lambda x: x[1]['P_T'], 
            reverse=True
        )
        
        report += "| –ù–∞–≤—ã–∫ ID | P(L0) | P(T) | P(G) | P(S) |\n"
        report += "|----------|-------|------|------|------|\n"
        
        for skill_id, params in sorted_skills[:10]:
            report += f"| {skill_id} | {params['P_L0']:.3f} | {params['P_T']:.3f} | {params['P_G']:.3f} | {params['P_S']:.3f} |\n"
        
        if len(sorted_skills) > 10:
            report += f"\n*... –∏ –µ—â–µ {len(sorted_skills) - 10} –Ω–∞–≤—ã–∫–æ–≤*\n"
        
        report += f"""
---

## üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–ê–†–ê–ú–ï–¢–†–û–í

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ú–∏–Ω–∏–º—É–º | –ú–∞–∫—Å–∏–º—É–º | –°—Ä–µ–¥–Ω–µ–µ | –°—Ç–¥. –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ |
|----------|---------|----------|---------|-----------------|
| **P(L0)** | {min(p['P_L0'] for p in model_params.values()):.3f} | {max(p['P_L0'] for p in model_params.values()):.3f} | {np.mean([p['P_L0'] for p in model_params.values()]):.3f} | {np.std([p['P_L0'] for p in model_params.values()]):.3f} |
| **P(T)** | {min(p['P_T'] for p in model_params.values()):.3f} | {max(p['P_T'] for p in model_params.values()):.3f} | {np.mean([p['P_T'] for p in model_params.values()]):.3f} | {np.std([p['P_T'] for p in model_params.values()]):.3f} |
| **P(G)** | {min(p['P_G'] for p in model_params.values()):.3f} | {max(p['P_G'] for p in model_params.values()):.3f} | {np.mean([p['P_G'] for p in model_params.values()]):.3f} | {np.std([p['P_G'] for p in model_params.values()]):.3f} |
| **P(S)** | {min(p['P_S'] for p in model_params.values()):.3f} | {max(p['P_S'] for p in model_params.values()):.3f} | {np.mean([p['P_S'] for p in model_params.values()]):.3f} | {np.std([p['P_S'] for p in model_params.values()]):.3f} |

---

## ‚úÖ –ì–û–¢–û–í–ù–û–°–¢–¨ –ö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ

–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ —Å–∏—Å—Ç–µ–º–µ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è:

1. **–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Å–≤–æ–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤** —Å—Ç—É–¥–µ–Ω—Ç–∞–º–∏
2. **–û—Ü–µ–Ω–∫–∞ –æ—Å–≤–æ–µ–Ω–∏—è –∫—É—Ä—Å–æ–≤** –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–≤—ã–∫–æ–≤
3. **–£—á–µ—Ç –≥—Ä–∞—Ñ–∞ –Ω–∞–≤—ã–∫–æ–≤** –ø—Ä–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–∏
4. **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∑–∞–¥–∞–Ω–∏–π** —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º–∏ –≤–µ—Å–∞–º–∏

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:
- ‚úÖ –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç {validation_results['accuracy']:.1%} —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- ‚úÖ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ–±—É—á–µ–Ω–∏—è
- ‚úÖ –ì–æ—Ç–æ–≤–∞ –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏

**–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É!** üöÄ
"""
        
        return report
    
    def optimize(self) -> Dict[str, str]:
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏"""
        print("üöÄ –ó–ê–ü–£–°–ö –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò BKT –ú–û–î–ï–õ–ò")
        print("=" * 60)
        
        # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        df = self.load_dataset()
        
        # 2. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        training_data, validation_data = self.prepare_training_data(df)
        
        # 3. –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        results = self.train_model(training_data, validation_data)
        
        # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        files = self.save_model(results)
        
        print("\nüéâ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
        print(f"üìä –¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {results['validation']['accuracy']:.1%}")
        print(f"üìÇ –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: optimized_bkt_model/")
        
        return files

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏"""
    print("üîß –û–ü–¢–ò–ú–ò–ó–ê–¢–û–† –ü–ê–†–ê–ú–ï–¢–†–û–í BKT –ú–û–î–ï–õ–ò")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
    optimizer = BKTOptimizer("bkt_training_data/bkt_training_dataset.csv")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é
    files = optimizer.optimize()
    
    print(f"\nüéØ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
    print(f"–ó–∞–≥—Ä—É–∂–∞–π—Ç–µ –º–æ–¥–µ–ª—å –∏–∑: {files['model_pickle']}")

if __name__ == "__main__":
    main()
